// App.jsx - WebRTC ê¸°ë°˜ ìì„¸ ë¶„ì„ + ìŒì„± ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ (ê°œì„ )
import React, { useState, useEffect, useRef } from 'react';
import '../src/interview.css'

const BASE_URL = 'http://192.168.35.218:5001';

// SVG ì•„ì´ì½˜ë“¤
const Camera = () => (
  <svg width="64" height="64" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M23 19a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h4l2-3h6l2 3h4a2 2 0 0 1 2 2z" />
    <circle cx="12" cy="13" r="4" />
  </svg>
);

const AlertCircle = ({ className = "" }) => (
  <svg className={className} width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <circle cx="12" cy="12" r="10" />
    <line x1="12" y1="8" x2="12" y2="12" />
    <line x1="12" y1="16" x2="12.01" y2="16" />
  </svg>
);

const VolumeX = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5" />
    <line x1="23" y1="9" x2="17" y2="15" />
    <line x1="17" y1="9" x2="23" y2="15" />
  </svg>
);

const Volume2 = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5" />
    <path d="M19.07 4.93a10 10 0 0 1 0 14.14M15.54 8.46a5 5 0 0 1 0 7.07" />
  </svg>
);

const MessageSquare = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z" />
  </svg>
);

const Brain = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M12 2a3 3 0 0 0-3 3 4 4 0 0 0-4 4v6a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V9a4 4 0 0 0-4-4 3 3 0 0 0-3-3z" />
    <path d="M12 9v4" />
    <path d="M12 17v.01" />
  </svg>
);

const Mic = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3z" />
    <path d="M19 10v2a7 7 0 0 1-14 0v-2" />
    <line x1="12" y1="19" x2="12" y2="23" />
    <line x1="8" y1="23" x2="16" y2="23" />
  </svg>
);

const MicOff = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <line x1="1" y1="1" x2="23" y2="23" />
    <path d="M9 9v3a3 3 0 0 0 5.12 2.12" />
    <path d="M15 9.34V5a3 3 0 0 0-5.94-.6" />
    <path d="M17 16.95A7 7 0 0 1 5 12v-2" />
    <path d="M19 10v2a7 7 0 0 1-.11 1.23" />
    <line x1="12" y1="19" x2="12" y2="23" />
    <line x1="8" y1="23" x2="16" y2="23" />
  </svg>
);

const BarChart = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <line x1="12" y1="20" x2="12" y2="10" />
    <line x1="18" y1="20" x2="18" y2="4" />
    <line x1="6" y1="20" x2="6" y2="16" />
  </svg>
);

export default function InterviewPostureVoiceApp() {
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isServerConnected, setIsServerConnected] = useState(false);
  const [currentIssues, setCurrentIssues] = useState([]);
  const [postureScore, setPostureScore] = useState(100);
  const [cameraLoading, setCameraLoading] = useState(false);
  
  // ìŒì„± ê´€ë ¨ ìƒíƒœ
  const [voiceEnabled, setVoiceEnabled] = useState(true);
  const [voiceAnalysisEnabled, setVoiceAnalysisEnabled] = useState(true);
  const [voiceAnalysisActive, setVoiceAnalysisActive] = useState(false);
  const [voiceLevel, setVoiceLevel] = useState(0);
  const [voiceAnalysisReport, setVoiceAnalysisReport] = useState(null);
  const [showVoiceReport, setShowVoiceReport] = useState(false);
  
  // ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ìƒíƒœ
  const [micTestActive, setMicTestActive] = useState(false);
  const [micTestResults, setMicTestResults] = useState(null);
  
  // ë¦¬í¬íŠ¸ í‘œì‹œ í”Œë˜ê·¸
  const reportShownRef = useRef(false);
  const lastReportTimestampRef = useRef(0);
  const checkIntervalRef = useRef(null); // interval ID ì €ì¥
  
  // ë©´ì ‘ ê´€ë ¨ ìƒíƒœ
  const [interviewData, setInterviewData] = useState({
    active: false,
    current_question: null,
    category: null,
    question_number: 0,
    total_questions: 0,
    phase: 'thinking',
    time_remaining: 0,
    current_stage: null
  });
  
  // WebRTC ê´€ë ¨ refs
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const streamRef = useRef(null);
  const frameIntervalRef = useRef(null);
  const calibrationTimeoutRef = useRef(null);
  const prevPhaseRef = useRef('');
  const prevActiveRef = useRef(false);
  
  // MediaRecorder ê´€ë ¨ refs
  const mediaRecorderRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const speechRecognitionRef = useRef(null);
  const chunkCountRef = useRef(0);
  const voiceLevelIntervalRef = useRef(null);
  
  // ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ refs
  const micTestIntervalRef = useRef(null);
  const micTestAudioContextRef = useRef(null);
  
  const lastQuestionRef = useRef('');
  const lastIssueTimeRef = useRef({});


  // Web Speech API ì´ˆê¸°í™”
  const initSpeechSynthesis = () => {
    if ('speechSynthesis' in window) {
      const loadVoices = () => {
        const voices = speechSynthesis.getVoices();
        return voices;
      };

      if (speechSynthesis.getVoices().length === 0) {
        speechSynthesis.addEventListener('voiceschanged', loadVoices, { once: true });
      }
      
      return true;
    }
    console.warn('Web Speech APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
    return false;
  };

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  const initSpeechRecognition = () => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      console.warn('Speech Recognition APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
      return false;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'ko-KR';
    
    recognition.onresult = (event) => {
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        
        if (event.results[i].isFinal) {
          sendSpeechTextToServer(transcript.trim());
        }
      }
    };
    
    recognition.onerror = (event) => {
      console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      if (event.error === 'not-allowed') {
        alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      }
    };
    
    recognition.onend = () => {
      if (voiceAnalysisActive && interviewData.active) {
        setTimeout(() => {
          try {
            recognition.start();
          } catch (e) {
            console.warn('ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì‹¤íŒ¨:', e);
          }
        }, 100);
      }
    };
    
    speechRecognitionRef.current = recognition;
    return true;
  };

  // ì„œë²„ë¡œ ìŒì„± í…ìŠ¤íŠ¸ ì „ì†¡
  const sendSpeechTextToServer = async (text) => {
    if (!voiceAnalysisActive || !interviewData.active || !text.trim()) return;
    
    try {
      console.log('ìŒì„± í…ìŠ¤íŠ¸ ì „ì†¡:', text);
      await fetch(`${BASE_URL}/voice/speech_text`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: text.trim(),
          timestamp: Date.now(),
          question_number: interviewData.question_number,
          phase: interviewData.phase
        })
      });
    } catch (error) {
      console.error('ìŒì„± í…ìŠ¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨:', error);
    }
  };

  // ìì„¸ í”¼ë“œë°± ìŒì„± ì¶œë ¥
  const speakIssue = (text) => {
    if (!voiceEnabled || !text) return;
    
    const now = Date.now();
    if (lastIssueTimeRef.current[text]) {
      const timeSinceLastSpeak = now - lastIssueTimeRef.current[text];
      if (timeSinceLastSpeak < 5000) return;
    }
    
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ko-KR';
      utterance.rate = 1.1;
      utterance.pitch = 1.2;
      utterance.volume = 0.7;
      
      speechSynthesis.speak(utterance);
      lastIssueTimeRef.current[text] = now;
    }
  };

  // WebRTC: ì¹´ë©”ë¼ ì‹œì‘
  const startCamera = async () => {
    try {
      console.log('ì¹´ë©”ë¼ ì‹œì‘ ì¤‘...');
      setCameraLoading(true);
      
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { 
          width: { ideal: 1280 },
          height: { ideal: 720 },
          facingMode: 'user'
        },
        audio: true
      });
      
      console.log('ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ íšë“ ì„±ê³µ');
      streamRef.current = stream;
      
      await new Promise((resolve) => {
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          
          videoRef.current.onloadedmetadata = () => {
            console.log('ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ');
            setCameraLoading(false);
            resolve();
          };
          
          videoRef.current.play()
            .then(() => console.log('ë¹„ë””ì˜¤ ì¬ìƒ ì‹œì‘'))
            .catch(err => console.error('ì¬ìƒ ì‹¤íŒ¨:', err));
        } else {
          setCameraLoading(false);
          resolve();
        }
      });
      
      console.log('ì¹´ë©”ë¼ ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ');
      return true;
      
    } catch (error) {
      console.error('ì¹´ë©”ë¼ ì‹œì‘ ì‹¤íŒ¨:', error);
      setCameraLoading(false);
      
      let errorMessage = 'ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:\n\n';
      
      if (error.name === 'NotAllowedError') {
        errorMessage += 'ì¹´ë©”ë¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní•´ê²°ë°©ë²•:\n1. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ ì™¼ìª½ ì•„ì´ì½˜ í´ë¦­\n2. ì¹´ë©”ë¼ ê¶Œí•œì„ "í—ˆìš©"ìœ¼ë¡œ ë³€ê²½\n3. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨';
      } else if (error.name === 'NotFoundError') {
        errorMessage += 'ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\ní™•ì¸ì‚¬í•­:\n- ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€\n- ë‹¤ë¥¸ ì•±ì—ì„œ ì¹´ë©”ë¼ ì‚¬ìš© ì¤‘ì¸ì§€';
      } else if (error.name === 'NotReadableError') {
        errorMessage += 'ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.';
      } else {
        errorMessage += error.message;
      }
      
      alert(errorMessage);
      return false;
    }
  };

  // WebRTC: í”„ë ˆì„ ì „ì†¡
  const startSendingFrames = () => {
    const canvas = canvasRef.current;
    const video = videoRef.current;
    
    if (!canvas || !video) {
      console.error('ìº”ë²„ìŠ¤ ë˜ëŠ” ë¹„ë””ì˜¤ ìš”ì†Œ ì—†ìŒ');
      return;
    }
    
    const ctx = canvas.getContext('2d');
    
    const waitForVideo = setInterval(() => {
      if (video.videoWidth > 0 && video.videoHeight > 0) {
        clearInterval(waitForVideo);
        
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        console.log('í”„ë ˆì„ ì „ì†¡ ì‹œì‘:', canvas.width, 'x', canvas.height);
        
        let frameCount = 0;
        let lastSendTime = 0;
        
        frameIntervalRef.current = setInterval(async () => {
          if (!video.videoWidth) return;
          
          // ì¢Œìš°ë°˜ì „ + ë¹„ë””ì˜¤ ê·¸ë¦¬ê¸°
          ctx.save();
          ctx.scale(-1, 1);
          ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
          ctx.restore();
          
          // ê°€ì´ë“œ í”„ë ˆì„ ê·¸ë¦¬ê¸°
          const guideFrame = {
            x_min: 0.25, x_max: 0.75,
            y_min: 0.15, y_max: 0.85
          };
          
          const x1 = canvas.width * guideFrame.x_min;
          const y1 = canvas.height * guideFrame.y_min;
          const x2 = canvas.width * guideFrame.x_max;
          const y2 = canvas.height * guideFrame.y_max;
          
          ctx.fillStyle = 'rgba(0, 0, 0, 0.3)';
          ctx.fillRect(0, 0, canvas.width, y1);
          ctx.fillRect(0, y2, canvas.width, canvas.height - y2);
          ctx.fillRect(0, y1, x1, y2 - y1);
          ctx.fillRect(x2, y1, canvas.width - x2, y2 - y1);
          
          ctx.strokeStyle = '#00ff00';
          ctx.lineWidth = 3;
          ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);
          
          frameCount++;
          
          const now = Date.now();
          if (now - lastSendTime < 333) return;
          lastSendTime = now;
          
          const frameData = canvas.toDataURL('image/jpeg', 0.5);
          
          try {
            const response = await fetch(`${BASE_URL}/analyze_frame`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({ frame: frameData })
            });
            
            if (response.ok) {
              const data = await response.json();
              
              if (data.posture_score !== undefined) {
                setPostureScore(data.posture_score);
              }
              
              if (data.issues && data.issues.length > 0) {
                setCurrentIssues(data.issues);
                
                if (!interviewData.active) {
                  data.issues.forEach((issue, index) => {
                    setTimeout(() => speakIssue(issue), index * 100);
                  });
                }
              } else if (data.issues) {
                setCurrentIssues([]);
              }
              
              if (data.interview) {
                updateInterviewData(data.interview);
              }
            }
          } catch (error) {
            if (frameCount % 50 === 0) {
              console.error('í”„ë ˆì„ ì „ì†¡ ì‹¤íŒ¨:', error);
            }
          }
        }, 100);
      }
    }, 100);
  };

  const stopSendingFrames = () => {
    if (frameIntervalRef.current) {
      clearInterval(frameIntervalRef.current);
      frameIntervalRef.current = null;
      console.log('í”„ë ˆì„ ì „ì†¡ ì¤‘ì§€');
    }
  };

  // ë©´ì ‘ ë°ì´í„° ì—…ë°ì´íŠ¸
  const updateInterviewData = (newData) => {
    const prevQuestion = interviewData.current_question;
    
    setInterviewData(newData);
    
    // ìƒˆ ì§ˆë¬¸ ìŒì„± ì¶œë ¥
    if (newData.current_question && 
        newData.current_question !== prevQuestion &&
        newData.phase === 'thinking') {
      setTimeout(() => speakQuestion(newData.current_question), 500);
    }
    
    // ë‹µë³€ ì‹œì‘ ì‹ í˜¸ìŒ (í•œ ë²ˆë§Œ)
    if (prevPhaseRef.current === 'thinking' && newData.phase === 'answering') {
      console.log('ğŸ”” ë‹µë³€ ì‹œì‘ ì‹ í˜¸ìŒ');
      playBeep();
    }
    
    // ë©´ì ‘ ì¢…ë£Œ ê°ì§€
    const isEnding = prevActiveRef.current && !newData.active && newData.phase === 'finished';
    
    if (isEnding) {
      console.log('========== ë©´ì ‘ ì¢…ë£Œ ê°ì§€ ==========');
      
      // ===== ì¤‘ë³µ ë°©ì§€: ì´ë¯¸ í™•ì¸ ì¤‘ì´ë©´ ìŠ¤í‚µ =====
      if (checkIntervalRef.current) {
        console.log('âš ï¸ ì´ë¯¸ ë¦¬í¬íŠ¸ í™•ì¸ ì¤‘ - ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€');
        prevPhaseRef.current = newData.phase;
        prevActiveRef.current = newData.active;
        return;
      }
      
      // ìŒì„± ë¶„ì„ ì¤‘ì§€
      stopVoiceAnalysis();
      
      // ë¦¬í¬íŠ¸ í™•ì¸ ì‹œì‘
      setTimeout(() => {
        checkVoiceReportPeriodically();
      }, 2000);
    }
    
    // ì´ì „ ìƒíƒœ ì €ì¥
    prevPhaseRef.current = newData.phase;
    prevActiveRef.current = newData.active;
  };
  
  const checkVoiceReportPeriodically = () => {
    // 1. ê¸°ì¡´ interval ì •ë¦¬
    if (checkIntervalRef.current) {
      console.log('âš ï¸ ê¸°ì¡´ ë¦¬í¬íŠ¸ í™•ì¸ interval ì •ë¦¬');
      clearInterval(checkIntervalRef.current);
      checkIntervalRef.current = null;
    }
    
    let attempts = 0;
    const maxAttempts = 30;
    
    console.log('ğŸ“Š ì£¼ê¸°ì  ë¦¬í¬íŠ¸ í™•ì¸ ì‹œì‘ (ìµœëŒ€ 30ì´ˆ)');
    
    const checkInterval = setInterval(async () => {
      attempts++;
      console.log(`ğŸ“Š ë¦¬í¬íŠ¸ í™•ì¸ ì¤‘... (${attempts}/${maxAttempts})`);
      
      try {
        const response = await fetch(`${BASE_URL}/voice/analysis_report`);
        
        if (!response.ok) {
          if (attempts >= maxAttempts) {
            clearInterval(checkInterval);
            checkIntervalRef.current = null;
            alert('ìŒì„± ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"ìŒì„± ë¶„ì„ ê²°ê³¼" ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‚˜ì¤‘ì— í™•ì¸í•˜ì„¸ìš”.');
          }
          return;
        }
        
        const data = await response.json();
        
        // 2. ë¦¬í¬íŠ¸ ë°œê²¬ ì‹œ
        if (data.overall_score !== undefined && 
            data.overall_score > 0 && 
            data.analysis_timestamp) {
          
          // 3. ì¤‘ë³µ ë°©ì§€: íƒ€ì„ìŠ¤íƒ¬í”„ ì²´í¬
          if (lastReportTimestampRef.current === data.analysis_timestamp) {
            console.log('âš ï¸ ì´ë¯¸ í‘œì‹œí•œ ë¦¬í¬íŠ¸ (íƒ€ì„ìŠ¤íƒ¬í”„ ì¼ì¹˜) - interval ì¢…ë£Œ');
            clearInterval(checkInterval);
            checkIntervalRef.current = null;
            return;
          }
          
          // 4. ì¤‘ë³µ ë°©ì§€: ì´ë¯¸ í‘œì‹œí–ˆëŠ”ì§€ ì²´í¬
          if (reportShownRef.current) {
            console.log('âš ï¸ ì´ë¯¸ ë¦¬í¬íŠ¸ í‘œì‹œë¨ - interval ì¢…ë£Œ');
            clearInterval(checkInterval);
            checkIntervalRef.current = null;
            return;
          }
          
          console.log('âœ… ìƒˆë¡œìš´ ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ìˆ˜ì‹ :', data);
          
          // íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
          lastReportTimestampRef.current = data.analysis_timestamp;
          reportShownRef.current = true;
          
          // ë¦¬í¬íŠ¸ í‘œì‹œ
          setVoiceAnalysisReport(data);
          setShowVoiceReport(true);
          
          // interval ì •ë¦¬
          clearInterval(checkInterval);
          checkIntervalRef.current = null;
          
          // í•œ ë²ˆë§Œ ì•Œë¦¼
          alert(`ìŒì„± ë¶„ì„ ì™„ë£Œ!\n\nì¢…í•© ì ìˆ˜: ${data.overall_score}ì `);
          
        } else if (attempts >= maxAttempts) {
          console.log('â° ë¦¬í¬íŠ¸ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼');
          clearInterval(checkInterval);
          checkIntervalRef.current = null;
          alert('ìŒì„± ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
        }
      } catch (error) {
        console.error('ë¦¬í¬íŠ¸ í™•ì¸ ì˜¤ë¥˜:', error);
        if (attempts >= maxAttempts) {
          clearInterval(checkInterval);
          checkIntervalRef.current = null;
        }
      }
    }, 1000);
    
    // interval ID ì €ì¥
    checkIntervalRef.current = checkInterval;
  };

  const playBeep = () => {
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const oscillator = audioContext.createOscillator();
      const gainNode = audioContext.createGain();
      
      oscillator.connect(gainNode);
      gainNode.connect(audioContext.destination);
      
      oscillator.frequency.value = 800;
      oscillator.type = 'sine';
      
      gainNode.gain.setValueAtTime(0.3, audioContext.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3);
      
      oscillator.start(audioContext.currentTime);
      oscillator.stop(audioContext.currentTime + 0.3);
    } catch (error) {
      console.error('ì‹ í˜¸ìŒ ì¬ìƒ ì‹¤íŒ¨:', error);
    }
  };

  const speakQuestion = (text) => {
    if (!voiceEnabled || !text) return;
    if (lastQuestionRef.current === text) return;
    lastQuestionRef.current = text;

    if ('speechSynthesis' in window) {
      speechSynthesis.cancel();

      const utterance = new SpeechSynthesisUtterance(text);
      const voices = speechSynthesis.getVoices();
      const koreanVoice = voices.find(voice => voice.lang.startsWith('ko'));
      
      if (koreanVoice) utterance.voice = koreanVoice;
      utterance.rate = 0.9;
      utterance.lang = 'ko-KR';

      speechSynthesis.speak(utterance);
    }
  };

  const stopSpeech = () => {
    if ('speechSynthesis' in window) {
      speechSynthesis.cancel();
      lastQuestionRef.current = '';
    }
  };

  // ë§ˆì´í¬ í…ŒìŠ¤íŠ¸
  const runMicrophoneTest = async () => {
    try {
      console.log('ì¢…í•© ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...');
      setMicTestActive(true);
      setMicTestResults(null);
      
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioDevices = devices.filter(device => device.kind === 'audioinput');
      
      if (audioDevices.length === 0) {
        throw new Error('ë§ˆì´í¬ ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
      
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
      }
      
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      analyser.fftSize = 2048;
      source.connect(analyser);
      
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      
      let testCount = 0;
      let maxVolume = 0;
      let volumeSum = 0;
      let signalCount = 0;
      const maxCount = 100;
      
      micTestIntervalRef.current = setInterval(() => {
        analyser.getByteFrequencyData(dataArray);
        
        const sum = dataArray.reduce((a, b) => a + b, 0);
        const average = sum / bufferLength;
        const volume = (average / 128) * 100;
        
        if (average > 5) signalCount++;
        
        maxVolume = Math.max(maxVolume, volume);
        volumeSum += volume;
        setVoiceLevel(volume);
        
        testCount++;
        
        if (testCount >= maxCount) {
          clearInterval(micTestIntervalRef.current);
          
          const results = {
            maxVolume,
            avgVolume: volumeSum / testCount,
            signalDetected: signalCount > 0,
            signalRatio: (signalCount / testCount) * 100
          };
          
          stream.getTracks().forEach(track => track.stop());
          audioContext.close();
          
          setMicTestActive(false);
          setMicTestResults(results);
          setVoiceLevel(0);
          
          alert(`ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n\nìµœëŒ€ ë³¼ë¥¨: ${results.maxVolume.toFixed(1)}%\ní‰ê·  ë³¼ë¥¨: ${results.avgVolume.toFixed(1)}%\nì‹ í˜¸ ê°ì§€: ${results.signalDetected ? 'í™•ì¸' : 'ê°ì§€ ì•ˆë¨'}`);
        }
      }, 100);
      
    } catch (error) {
      console.error('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error);
      setMicTestActive(false);
      alert('ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: ' + error.message);
    }
  };

  const stopMicTest = () => {
    if (micTestIntervalRef.current) {
      clearInterval(micTestIntervalRef.current);
    }
    setMicTestActive(false);
    setVoiceLevel(0);
  };

  // MediaRecorder ì´ˆê¸°í™”
  const initMediaRecorderAnalysis = async () => {
    try {
      console.log('MediaRecorder ì´ˆê¸°í™” ì‹œì‘');
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100,
          channelCount: 1
        } 
      });
      
      console.log('ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“ ì„±ê³µ');
      
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        console.log('ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒíƒœ:', {
          enabled: audioTrack.enabled,
          muted: audioTrack.muted,
          readyState: audioTrack.readyState,
          label: audioTrack.label
        });
        
        audioTrack.onended = () => console.log('ì˜¤ë””ì˜¤ íŠ¸ë™ ì¢…ë£Œë¨');
        audioTrack.onmute = () => console.log('ì˜¤ë””ì˜¤ íŠ¸ë™ ìŒì†Œê±°ë¨');
        audioTrack.onunmute = () => console.log('ì˜¤ë””ì˜¤ íŠ¸ë™ ìŒì†Œê±° í•´ì œë¨');
      }
      
      mediaStreamRef.current = stream;
      
      let mimeType = 'audio/webm;codecs=opus';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/mp4';
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'audio/wav';
          }
        }
      }
      
      console.log('ì‚¬ìš©í•  ì˜¤ë””ì˜¤ í˜•ì‹:', mimeType);
      
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType,
        audioBitsPerSecond: 128000
      });
      
      let audioChunks = [];
      chunkCountRef.current = 0;
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunkCountRef.current++;
          console.log(`ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  #${chunkCountRef.current} - í¬ê¸°: ${event.data.size} bytes`);
          
          audioChunks.push(event.data);
          
          // ì¦‰ì‹œ ì„œë²„ ì „ì†¡ (await ì—†ì´ ì‹¤í–‰)
          sendAudioChunkToServer(event.data, chunkCountRef.current)
            .then(() => {
              console.log(`âœ… ì²­í¬ #${chunkCountRef.current} ì„œë²„ ì „ì†¡ ì„±ê³µ`);
            })
            .catch(err => {
              console.error(`âŒ ì²­í¬ #${chunkCountRef.current} ì „ì†¡ ì‹¤íŒ¨:`, err);
            });
        } else {
          console.warn(`ë¹ˆ ì²­í¬ ê°ì§€ #${chunkCountRef.current}`);
        }
      };
      
      mediaRecorder.onstop = () => {
        console.log(`MediaRecorder ì¤‘ì§€ - ì´ ${chunkCountRef.current}ê°œ ì²­í¬ ìˆ˜ì§‘`);
        const audioBlob = new Blob(audioChunks, { type: mimeType });
        console.log('ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸°:', audioBlob.size, 'bytes');
        
        if (audioBlob.size > 0) {
          console.log('ğŸ“¤ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì„œë²„ ì „ì†¡ ì‹œì‘...');
          sendFinalAudioToServer(audioBlob)
            .then(() => {
              console.log('âœ… ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì™„ë£Œ');
            })
            .catch(err => {
              console.error('âŒ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì‹¤íŒ¨:', err);
            });
        } else {
          console.error('ìµœì¢… ì˜¤ë””ì˜¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!');
        }
        
        audioChunks = [];
        chunkCountRef.current = 0;
      };
      
      mediaRecorder.onerror = (event) => {
        console.error('MediaRecorder ì˜¤ë¥˜:', event.error);
      };
      
      mediaRecorder.onstart = () => {
        console.log('MediaRecorder ë…¹ìŒ ì‹œì‘ë¨');
      };
      
      mediaRecorderRef.current = mediaRecorder;
      
      console.log('MediaRecorder ì´ˆê¸°í™” ì™„ë£Œ!');
      return true;
      
    } catch (error) {
      console.error('MediaRecorder ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      
      let errorMessage = '';
      
      if (error.name === 'NotAllowedError') {
        errorMessage = 'ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní•´ê²° ë°©ë²•:\n1. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ ì™¼ìª½ ì•„ì´ì½˜ í´ë¦­\n2. ë§ˆì´í¬ ê¶Œí•œì„ "í—ˆìš©"ìœ¼ë¡œ ë³€ê²½\n3. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨';
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'MediaRecorderë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤. Chrome, Firefox, Safarië¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.';
      } else {
        errorMessage = `ë§ˆì´í¬ ì˜¤ë¥˜: ${error.message}`;
      }
      
      alert(errorMessage);
      return false;
    }
  };

  // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸°
  const initRealTimeAudioAnalyzer = async () => {
    if (!mediaStreamRef.current) {
      console.error('ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ì´ ì—†ìŠµë‹ˆë‹¤.');
      return false;
    }
    
    try {
      console.log('ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘...');
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      console.log('AudioContext ìƒì„±:', audioContext.state);
      
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
        console.log('AudioContext resume ì™„ë£Œ:', audioContext.state);
      }
      
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(mediaStreamRef.current);
      
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.8;
      source.connect(analyser);
      
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      
      console.log('ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì„¤ì • ì™„ë£Œ - ë²„í¼ í¬ê¸°:', bufferLength);
      
      let frameCount = 0;
      
      const updateVolume = () => {
        analyser.getByteFrequencyData(dataArray);
        
        const sum = dataArray.reduce((a, b) => a + b, 0);
        const average = sum / bufferLength;
        const volume = Math.min(100, (average / 128) * 100);
        
        setVoiceLevel(volume);
        
        frameCount++;
        
        if (frameCount % 100 === 0) {
          console.log(`ì‹¤ì‹œê°„ ë³¼ë¥¨: ${volume.toFixed(1)}% (í‰ê· : ${average.toFixed(1)})`);
        }
        
        requestAnimationFrame(updateVolume);
      };
      
      updateVolume();
      console.log('ì‹¤ì‹œê°„ ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘!');
      
      voiceLevelIntervalRef.current = audioContext;
      
      return true;
      
    } catch (error) {
      console.error('ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      return false;
    }
  };

  const stopVoiceLevelSimulation = () => {
    if (voiceLevelIntervalRef.current) {
      if (typeof voiceLevelIntervalRef.current.close === 'function') {
        voiceLevelIntervalRef.current.close();
      } else {
        clearInterval(voiceLevelIntervalRef.current);
      }
      voiceLevelIntervalRef.current = null;
    }
    setVoiceLevel(0);
  };

  const sendAudioChunkToServer = async (audioBlob, chunkNumber) => {
    try {
      console.log(`ğŸ“¤ ì²­í¬ #${chunkNumber} ì„œë²„ ì „ì†¡ ì‹œì‘... (${audioBlob.size} bytes)`);
      
      const formData = new FormData();
      formData.append('audio', audioBlob, `chunk_${chunkNumber}.webm`);
      formData.append('chunk_number', chunkNumber);
      formData.append('timestamp', Date.now());
      formData.append('question_number', interviewData.question_number || 0);
      formData.append('phase', interviewData.phase || 'unknown');
      
      console.log(`ğŸ“¡ ì²­í¬ #${chunkNumber} ìš”ì²­ URL: ${BASE_URL}/voice/audio_chunk_blob`);
      
      const response = await fetch(`${BASE_URL}/voice/audio_chunk_blob`, {
        method: 'POST',
        body: formData
      });
      
      console.log(`ğŸ“¥ ì²­í¬ #${chunkNumber} ì„œë²„ ì‘ë‹µ ìƒíƒœ: ${response.status}`);
      
      if (response.ok) {
        const result = await response.json();
        console.log(`âœ… ì²­í¬ #${chunkNumber} ì „ì†¡ ì„±ê³µ:`, result);
      } else {
        const errorText = await response.text();
        console.error(`âŒ ì²­í¬ #${chunkNumber} ì„œë²„ ì—ëŸ¬ (${response.status}):`, errorText);
      }
    } catch (error) {
      console.error(`âŒ ì²­í¬ #${chunkNumber} ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜:`, error);
      console.error('ì—ëŸ¬ ìƒì„¸:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
    }
  };

  const sendFinalAudioToServer = async (audioBlob) => {
    try {
      console.log(`ğŸ“¤ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì„œë²„ ì „ì†¡ ì‹œì‘... (${audioBlob.size} bytes)`);
      
      const formData = new FormData();
      formData.append('final_audio', audioBlob, 'final_audio.webm');
      formData.append('timestamp', Date.now());
      
      console.log(`ğŸ“¡ ìµœì¢… ì˜¤ë””ì˜¤ ìš”ì²­ URL: ${BASE_URL}/voice/final_audio`);
      
      const response = await fetch(`${BASE_URL}/voice/final_audio`, {
        method: 'POST',
        body: formData
      });
      
      console.log(`ğŸ“¥ ìµœì¢… ì˜¤ë””ì˜¤ ì„œë²„ ì‘ë‹µ ìƒíƒœ: ${response.status}`);
      
      if (response.ok) {
        const result = await response.json();
        console.log('âœ… ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì„±ê³µ:', result);
      } else {
        const errorText = await response.text();
        console.error(`âŒ ìµœì¢… ì˜¤ë””ì˜¤ ì„œë²„ ì—ëŸ¬ (${response.status}):`, errorText);
      }
    } catch (error) {
      console.error('âŒ ìµœì¢… ì˜¤ë””ì˜¤ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜:', error);
      console.error('ì—ëŸ¬ ìƒì„¸:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
    }
  };

  const startVoiceAnalysisSession = async () => {
    if (!voiceAnalysisEnabled) {
      console.log('ìŒì„± ë¶„ì„ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      return false;
    }
    
    console.log('MediaRecorder ìŒì„± ë¶„ì„ ì„¸ì…˜ ì‹œì‘...');
    setVoiceAnalysisActive(true);
    
    const success = await initMediaRecorderAnalysis();
    
    if (success && mediaRecorderRef.current) {
      try {
        mediaRecorderRef.current.start(100);
        console.log('MediaRecorder ë…¹ìŒ ì‹œì‘ (100ms ì²­í¬)');
        
        await initRealTimeAudioAnalyzer();
        
        if (speechRecognitionRef.current) {
          speechRecognitionRef.current.start();
          console.log('ìŒì„± ì¸ì‹ ì‹œì‘');
        }
        
        return true;
      } catch (error) {
        console.error('MediaRecorder ì‹œì‘ ì‹¤íŒ¨:', error);
        setVoiceAnalysisActive(false);
        return false;
      }
    } else {
      console.error('MediaRecorder ì´ˆê¸°í™” ì‹¤íŒ¨');
      setVoiceAnalysisActive(false);
      return false;
    }
  };

  const stopVoiceAnalysis = () => {
    console.log('MediaRecorder ìŒì„± ë¶„ì„ ì¤‘ì§€ ì‹œì‘...');
    setVoiceAnalysisActive(false);
    
    stopVoiceLevelSimulation();
    
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      try {
        mediaRecorderRef.current.stop();
        console.log('MediaRecorder ì¤‘ì§€ ì™„ë£Œ');
      } catch (error) {
        console.error('MediaRecorder ì¤‘ì§€ ì‹¤íŒ¨:', error);
      }
    }
    
    if (speechRecognitionRef.current) {
      try {
        speechRecognitionRef.current.stop();
        console.log('ìŒì„± ì¸ì‹ ì¤‘ì§€ ì™„ë£Œ');
      } catch (error) {
        console.error('ìŒì„± ì¸ì‹ ì¤‘ì§€ ì‹¤íŒ¨:', error);
      }
    }
    
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
      console.log('ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì™„ë£Œ');
    }
    
    mediaRecorderRef.current = null;
    
    console.log('MediaRecorder ìŒì„± ë¶„ì„ ì™„ì „ ì¤‘ì§€');
  };

  const startAnalysis = async () => {
    if (!isServerConnected) {
      alert('ì„œë²„ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\nì„œë²„ ì£¼ì†Œ: ' + BASE_URL);
      return;
    }
    
    // ========== ì™„ì „ ì´ˆê¸°í™” ==========
    console.log('========== ì™„ì „ ì´ˆê¸°í™” ==========');
    
    // 1. interval ì •ë¦¬
    if (checkIntervalRef.current) {
      clearInterval(checkIntervalRef.current);
      checkIntervalRef.current = null;
      console.log('âœ… interval ì •ë¦¬');
    }
    
    // 2. ë¦¬í¬íŠ¸ ì´ˆê¸°í™”
    setVoiceAnalysisReport(null);
    setShowVoiceReport(false);
    console.log('âœ… ë¦¬í¬íŠ¸ ìƒíƒœ ì´ˆê¸°í™”');
    
    // 3. í”Œë˜ê·¸ ë¦¬ì…‹
    reportShownRef.current = false;
    lastReportTimestampRef.current = 0;
    console.log('âœ… í”Œë˜ê·¸ ë¦¬ì…‹');
    
    // 4. ë©´ì ‘ ë°ì´í„° ì´ˆê¸°í™”
    setInterviewData({
      active: false,
      current_question: null,
      category: null,
      question_number: 0,
      total_questions: 0,
      phase: 'thinking',
      time_remaining: 0,
      current_stage: null
    });
    console.log('âœ… ë©´ì ‘ ë°ì´í„° ì´ˆê¸°í™”');
    
    console.log('========== ğŸ¯ ìì„¸ ë¶„ì„ ì‹œì‘ ==========');
    
    // 1. ì¹´ë©”ë¼ ì‹œì‘
    console.log('1ï¸âƒ£ ì¹´ë©”ë¼ ì‹œì‘ ì‹œë„...');
    const cameraStarted = await startCamera();
    if (!cameraStarted) {
      console.error('âŒ ì¹´ë©”ë¼ ì‹œì‘ ì‹¤íŒ¨ë¡œ ë¶„ì„ ì¤‘ë‹¨');
      return;
    }
    console.log('âœ… 1/3: ì¹´ë©”ë¼ ì‹œì‘ ì™„ë£Œ');
    
    // 2. ì„œë²„ì— ë¶„ì„ ì‹œì‘ ìš”ì²­
    try {
      console.log('2ï¸âƒ£ ì„œë²„ì— ë¶„ì„ ì‹œì‘ ìš”ì²­...');
      const response = await fetch(`${BASE_URL}/start_analysis`, { method: 'POST' });
      
      if (!response.ok) {
        throw new Error('ì„œë²„ ì‘ë‹µ ì‹¤íŒ¨: ' + response.status);
      }
      
      const data = await response.json();
      console.log('âœ… 2/3: ì„œë²„ ë¶„ì„ ì‹œì‘:', data);
      
      // ì¦‰ì‹œ í”„ë ˆì„ ì „ì†¡ ì‹œì‘
      console.log('========== ğŸ“¸ í”„ë ˆì„ ì „ì†¡ ì‹œì‘ ==========');
      startSendingFrames();
      
      alert('5ì´ˆê°„ ë°”ë¥¸ ìì„¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”!\nìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ì§„í–‰ë©ë‹ˆë‹¤.');
      
      // 3. 5ì´ˆ í›„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ
      calibrationTimeoutRef.current = setTimeout(async () => {
        try {
          console.log('3ï¸âƒ£ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ ìš”ì²­...');
          const calibResponse = await fetch(`${BASE_URL}/finalize_calibration`, { method: 'POST' });
          
          if (calibResponse.ok) {
            const calibData = await calibResponse.json();
            console.log('âœ… 3/3: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ:', calibData);
            console.log('========== ğŸ‰ ìì„¸ ë¶„ì„ í™œì„±í™” ì™„ë£Œ ==========');
            
            setIsAnalyzing(true);
          } else {
            const errorData = await calibResponse.json();
            console.error('âŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨:', errorData);
            alert(`ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤íŒ¨: ${errorData.message || 'ìƒ˜í”Œ ë¶€ì¡±'}`);
            
            stopSendingFrames();
            if (streamRef.current) {
              streamRef.current.getTracks().forEach(track => track.stop());
            }
          }
        } catch (error) {
          console.error('âŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìš”ì²­ ì‹¤íŒ¨:', error);
          alert('ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì˜¤ë¥˜: ' + error.message);
          
          stopSendingFrames();
          if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
          }
        }
      }, 5000);
      
    } catch (error) {
      console.error('âŒ ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:', error);
      alert('ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:\n' + error.message);
      
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    }
  };

  const stopAnalysis = async () => {
    try {
      console.log('========== ë¶„ì„ ì¤‘ì§€ ==========');
      
      // 1. interval ì •ë¦¬
      if (checkIntervalRef.current) {
        clearInterval(checkIntervalRef.current);
        checkIntervalRef.current = null;
        console.log('âœ… interval ì •ë¦¬');
      }
      
      // 2. ë¦¬í¬íŠ¸ ë‹«ê¸° (ë°ì´í„°ëŠ” ìœ ì§€)
      setShowVoiceReport(false);
      
      // 3. ì„œë²„ ì¤‘ì§€ ìš”ì²­
      await fetch(`${BASE_URL}/stop_analysis`, { method: 'POST' });
      
      if (calibrationTimeoutRef.current) {
        clearTimeout(calibrationTimeoutRef.current);
      }
      
      stopSendingFrames();
      stopSpeech();
      stopVoiceAnalysis();
      
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      
      setIsAnalyzing(false);
      
      if (interviewData.active) {
        await stopInterview();
      }
      
      console.log('âœ… ë¶„ì„ ì™„ì „ ì¤‘ì§€');
    } catch (error) {
      console.error('ë¶„ì„ ì¤‘ì§€ ì‹¤íŒ¨:', error);
    }
  };

const startInterview = async () => {
  try {
    // ========== ì™„ì „ ì´ˆê¸°í™” ==========
    console.log('========== ë©´ì ‘ ì‹œì‘ - ì™„ì „ ì´ˆê¸°í™” ==========');
    
    // 1. interval ì •ë¦¬
    if (checkIntervalRef.current) {
      clearInterval(checkIntervalRef.current);
      checkIntervalRef.current = null;
    }
    
    // 2. ë¦¬í¬íŠ¸ ì´ˆê¸°í™”
    setVoiceAnalysisReport(null);
    setShowVoiceReport(false);
    
    // 3. í”Œë˜ê·¸ ë¦¬ì…‹
    reportShownRef.current = false;
    lastReportTimestampRef.current = 0;
    
    console.log('âœ… ì´ˆê¸°í™” ì™„ë£Œ');
    
    console.log('========== ğŸ¬ ë©´ì ‘ ì‹œì‘ ==========');
    
    const response = await fetch(`${BASE_URL}/interview/start`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' }
    });
    
    if (response.ok) {
      const data = await response.json();
      console.log('âœ… ë©´ì ‘ ì‹œì‘ ì‘ë‹µ:', data);
      
      setInterviewData({
        active: true,
        current_question: data.current_question,
        category: data.category,
        question_number: 1,
        total_questions: data.total_questions,
        phase: 'thinking',
        time_remaining: 10,
        current_stage: data.flow_stage
      });

      // ìŒì„± ë¶„ì„ ì‹œì‘
      if (voiceAnalysisEnabled) {
        console.log('ğŸ¤ ìŒì„± ë¶„ì„ í™œì„±í™” ì‹œë„...');
        const voiceStarted = await startVoiceAnalysisSession();
        if (voiceStarted) {
          console.log('âœ… ìŒì„± ë¶„ì„ í™œì„±í™” ì„±ê³µ');
        } else {
          console.error('âŒ ìŒì„± ë¶„ì„ í™œì„±í™” ì‹¤íŒ¨');
          alert('ìŒì„± ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\në§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
        }
      }

      setTimeout(() => speakQuestion(data.current_question), 1000);
      
      console.log('========== ğŸ‰ ë©´ì ‘ ì¤€ë¹„ ì™„ë£Œ ==========');
    }
  } catch (error) {
    console.error('âŒ ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨:', error);
    alert('ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨: ' + error.message);
  }
};

  const stopInterview = async () => {
    try {
      await fetch(`${BASE_URL}/interview/stop`, { method: 'POST' });
      stopSpeech();
      stopVoiceAnalysis();
      
      setInterviewData({
        active: false,
        current_question: null,
        phase: 'thinking'
      });

      setTimeout(fetchVoiceAnalysisReport, 2000);
    } catch (error) {
      console.error('ë©´ì ‘ ì¤‘ì§€ ì‹¤íŒ¨:', error);
    }
  };

  const fetchVoiceAnalysisReport = async () => {
    // ì´ë¯¸ ë¦¬í¬íŠ¸ê°€ í‘œì‹œë˜ì—ˆë‹¤ë©´ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
    if (reportShownRef.current) {
      return;
    }
    
    try {
      const response = await fetch(`${BASE_URL}/voice/analysis_report`);
      
      if (!response.ok) {
        return;
      }
      
      const data = await response.json();
      
      if (data.overall_score !== undefined && 
          data.overall_score > 0 && 
          data.analysis_timestamp) {
        
        // ì´ë¯¸ ì²˜ë¦¬í•œ íƒ€ì„ìŠ¤íƒ¬í”„ì¸ì§€ í™•ì¸
        if (lastReportTimestampRef.current === data.analysis_timestamp) {
          return;
        }
        
        reportShownRef.current = true;
        lastReportTimestampRef.current = data.analysis_timestamp;
        
        setVoiceAnalysisReport(data);
        setShowVoiceReport(true);
      }
    } catch (error) {
      console.error('ë¦¬í¬íŠ¸ í™•ì¸ ì‹¤íŒ¨:', error);
    }
  };

  const forceCheckVoiceReport = async () => {
    try {
      console.log('========== ìˆ˜ë™ ë¦¬í¬íŠ¸ í™•ì¸ ==========');
      const response = await fetch(`${BASE_URL}/voice/analysis_report`);
      
      if (!response.ok) {
        throw new Error(`ì„œë²„ ì‘ë‹µ ì‹¤íŒ¨: ${response.status}`);
      }
      
      const data = await response.json();
      
      if (data.overall_score !== undefined && data.overall_score > 0) {
        console.log('ë¦¬í¬íŠ¸ ë°œê²¬!');
        
        // ìˆ˜ë™ í™•ì¸ ì‹œì—ë§Œ íƒ€ì„ìŠ¤íƒ¬í”„ ê°•ì œ ì—…ë°ì´íŠ¸
        if (data.analysis_timestamp) {
          lastReportTimestampRef.current = data.analysis_timestamp;
        }
        reportShownRef.current = true;
        
        setVoiceAnalysisReport(data);
        setShowVoiceReport(true);
      } else if (data.message) {
        alert(`ìŒì„± ë¶„ì„ ìƒíƒœ:\n\n${data.message}`);
      } else {
        alert('ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      }
    } catch (error) {
      console.error('ë¦¬í¬íŠ¸ í™•ì¸ ì‹¤íŒ¨:', error);
      alert(`ë¦¬í¬íŠ¸ í™•ì¸ ì‹¤íŒ¨:\n\n${error.message}`);
    }
  };

  useEffect(() => {
    const checkServer = async () => {
      try {
        const response = await fetch(`${BASE_URL}/health`);
        setIsServerConnected(response.ok);
      } catch {
        setIsServerConnected(false);
      }
    };

    checkServer();
    const interval = setInterval(checkServer, 10000);
    return () => clearInterval(interval);
  }, []);

// ì»´í¬ë„ŒíŠ¸ ì •ë¦¬ useEffect ìˆ˜ì •
useEffect(() => {
  return () => {
    console.log('ì»´í¬ë„ŒíŠ¸ ì •ë¦¬');
    
    // interval ì •ë¦¬
    if (checkIntervalRef.current) {
      clearInterval(checkIntervalRef.current);
      checkIntervalRef.current = null;
    }
    
    stopSendingFrames();
    stopSpeech();
    stopVoiceAnalysis();
    stopMicTest();
  };
}, []);




  const getScoreClass = (score) => {
    if (score >= 80) return 'score-excellent';
    if (score >= 60) return 'score-good';
    return 'score-poor';
  };

  const getPhaseText = (phase) => {
    switch (phase) {
      case 'thinking': return 'ìƒê° ì‹œê°„';
      case 'answering': return 'ë‹µë³€ ì‹œê°„';
      case 'finished': return 'ì™„ë£Œ';
      default: return 'ëŒ€ê¸°';
    }
  };

  const getVoiceLevelColor = (level) => {
    if (level < 20) return '#999';
    if (level < 50) return '#ffeb3b';
    if (level < 80) return '#4caf50';
    return '#ff5722';
  };

  return (
    <div className="app-container">
      <div className="header">
        <h1>ì²´ìœ¡ëŒ€í•™ ìœ¡ìƒì „ê³µ ë©´ì ‘ ì—°ìŠµ (WebRTC ë°©ì‹)</h1>
        <div className={`connection-status ${isServerConnected ? 'connected' : 'disconnected'}`}>
          {isServerConnected ? 'ì„œë²„ ì—°ê²°ë¨' : 'ì„œë²„ ì—°ê²° ì•ˆë¨'}
        </div>
      </div>

      {!isAnalyzing && (
        <div style={{
          background: 'linear-gradient(135deg, #667eea, #764ba2)',
          color: 'white',
          padding: '20px',
          borderRadius: '12px',
          margin: '20px 0',
          textAlign: 'center'
        }}>
          <h3 style={{ margin: '0 0 15px 0' }}>ë§ˆì´í¬ í…ŒìŠ¤íŠ¸</h3>
          <p style={{ margin: '0 0 15px 0', opacity: 0.9 }}>
            ë©´ì ‘ ì‹œì‘ ì „ì— ë§ˆì´í¬ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
          </p>
          
          <button
            onClick={micTestActive ? stopMicTest : runMicrophoneTest}
            disabled={isAnalyzing && !micTestActive}
            style={{
              background: micTestActive 
                ? 'linear-gradient(135deg, #ff6b6b, #ee5a24)' 
                : 'linear-gradient(135deg, #00d2ff, #3a7bd5)',
              color: 'white',
              border: 'none',
              padding: '15px 30px',
              borderRadius: '8px',
              cursor: 'pointer',
              fontSize: '16px',
              fontWeight: 'bold'
            }}
          >
            {micTestActive ? 'í…ŒìŠ¤íŠ¸ ì¤‘ì§€' : 'ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹œì‘'}
          </button>
          
          {micTestActive && (
            <div style={{ marginTop: '15px' }}>
              <div style={{ fontSize: '14px', marginBottom: '10px' }}>
                ì§€ê¸ˆ ë§ˆì´í¬ì— ë§í•´ë³´ì„¸ìš”! (10ì´ˆê°„ í…ŒìŠ¤íŠ¸)
              </div>
              <div style={{
                background: 'rgba(255,255,255,0.2)',
                borderRadius: '20px',
                height: '8px',
                overflow: 'hidden',
                margin: '10px auto',
                width: '200px'
              }}>
                <div style={{
                  width: `${voiceLevel}%`,
                  height: '100%',
                  background: getVoiceLevelColor(voiceLevel),
                  transition: 'width 0.1s ease'
                }}></div>
              </div>
              <div style={{ fontSize: '12px' }}>
                ë³¼ë¥¨: {Math.round(voiceLevel)}%
              </div>
            </div>
          )}
          
          {micTestResults && !micTestResults.error && (
            <div style={{
              background: micTestResults.signalDetected ? 'rgba(76, 175, 80, 0.2)' : 'rgba(244, 67, 54, 0.2)',
              padding: '10px',
              borderRadius: '8px',
              marginTop: '15px',
              fontSize: '14px'
            }}>
              <div>ìµœëŒ€: {micTestResults.maxVolume.toFixed(1)}% | í‰ê· : {micTestResults.avgVolume.toFixed(1)}%</div>
              <div>{micTestResults.signalDetected ? 'ë§ˆì´í¬ ì •ìƒ ì‘ë™!' : 'ì‹ í˜¸ ê°ì§€ ì•ˆë¨'}</div>
            </div>
          )}
        </div>
      )}

      {interviewData.active && interviewData.current_question && (
        <div className="interview-panel">
          <div className="interview-info">
            <div className="interview-meta">
              <span className="question-counter">ì§ˆë¬¸ {interviewData.question_number}/{interviewData.total_questions}</span>
              <span className="category-badge">{interviewData.category}</span>
              <span className={`phase-indicator ${interviewData.phase === 'thinking' ? 'phase-thinking' : 'phase-answering'}`}>
                {interviewData.phase === 'thinking' && <Brain />}
                {getPhaseText(interviewData.phase)}: {interviewData.time_remaining}ì´ˆ
              </span>
            </div>
            
            <div className="current-question">
              {interviewData.current_question}
            </div>
            
            {voiceAnalysisActive && (
              <div className="voice-analysis-panel">
                <div className="voice-indicator">
                  <Mic />
                  <span>ìŒì„± ë¶„ì„ ì¤‘</span>
                  <div className="voice-level-bar">
                    <div 
                      className="voice-level-fill"
                      style={{ 
                        width: `${voiceLevel}%`,
                        backgroundColor: getVoiceLevelColor(voiceLevel)
                      }}
                    ></div>
                  </div>
                  <span className="voice-level-text">{Math.round(voiceLevel)}%</span>
                </div>
              </div>
            )}
            
            <div className="interview-controls">
              <button className="btn-stop-interview" onClick={stopInterview}>
                ë©´ì ‘ ì¤‘ì§€
              </button>
            </div>
          </div>
        </div>
      )}

      <div className="video-container" style={{ position: 'relative' }}>
        <canvas 
          ref={canvasRef}
          style={{
            display: isAnalyzing ? 'block' : 'none',
            width: '100%',
            height: '100%',
            objectFit: 'contain',
            background: '#000'
          }}
        />
        
        <video 
          ref={videoRef}
          autoPlay
          playsInline
          muted
          style={{ display: 'none' }}
        />
        
        {cameraLoading && (
          <div style={{
            position: 'absolute',
            top: 0,
            left: 0,
            right: 0,
            bottom: 0,
            background: 'rgba(0, 0, 0, 0.8)',
            display: 'flex',
            flexDirection: 'column',
            alignItems: 'center',
            justifyContent: 'center',
            color: 'white',
            zIndex: 2000
          }}>
            <div style={{
              width: '60px',
              height: '60px',
              border: '5px solid rgba(255,255,255,0.3)',
              borderTop: '5px solid white',
              borderRadius: '50%',
              animation: 'spin 1s linear infinite'
            }}></div>
            <p style={{ marginTop: '20px', fontSize: '18px' }}>ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...</p>
            <style>{`
              @keyframes spin {
                0% { transform: rotate(0deg); }
                100% { transform: rotate(360deg); }
              }
            `}</style>
          </div>
        )}
        
        {currentIssues.length > 0 && (
          <div style={{
            position: 'absolute',
            top: '20px',
            left: '20px',
            background: 'rgba(255, 0, 0, 0.8)',
            color: 'white',
            padding: '15px',
            borderRadius: '8px',
            maxWidth: '300px',
            zIndex: 1000
          }}>
            <AlertCircle style={{ display: 'inline', marginRight: '8px' }} />
            <strong>ìì„¸ í”¼ë“œë°±:</strong>
            {currentIssues.map((issue, idx) => (
              <div key={idx} style={{ marginTop: '5px' }}>â€¢ {issue}</div>
            ))}
          </div>
        )}
        
        <div style={{
          position: 'absolute',
          top: '20px',
          right: '20px',
          background: postureScore >= 80 ? 'rgba(76, 175, 80, 0.9)' : 
                     postureScore >= 60 ? 'rgba(255, 193, 7, 0.9)' : 
                     'rgba(244, 67, 54, 0.9)',
          color: 'white',
          padding: '15px 25px',
          borderRadius: '50%',
          fontSize: '24px',
          fontWeight: 'bold',
          minWidth: '60px',
          minHeight: '60px',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          zIndex: 1000,
          boxShadow: '0 4px 12px rgba(0,0,0,0.3)'
        }}>
          {postureScore}
        </div>
        
        {!isAnalyzing && !cameraLoading && (
          <div className="video-placeholder">
            <Camera />
            <p>ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”</p>
            {!isServerConnected && (
              <p className="error-message">ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤</p>
            )}
          </div>
        )}
      </div>

      <div className="controls">
        <button
          onClick={isAnalyzing ? stopAnalysis : startAnalysis}
          disabled={!isServerConnected}
          className={`btn-main ${!isServerConnected ? 'disabled' : isAnalyzing ? 'stop' : 'start'}`}
        >
          {isAnalyzing ? 'ë¶„ì„ ì¤‘ì§€' : 'ë¶„ì„ ì‹œì‘'}
        </button>
        
        {isAnalyzing && !interviewData.active && (
          <button onClick={startInterview} className="btn-interview">
            <MessageSquare />
            ë©´ì ‘ ì‹œì‘
          </button>
        )}
        
        <button
          onClick={() => {
            setVoiceEnabled(!voiceEnabled);
            if (!voiceEnabled && interviewData.current_question) {
              speakQuestion(interviewData.current_question);
            } else {
              stopSpeech();
            }
          }}
          className={`btn-voice ${voiceEnabled ? 'voice-on' : 'voice-off'}`}
        >
          {voiceEnabled ? <Volume2 /> : <VolumeX />}
          {voiceEnabled ? ' ìŒì„± ON' : ' ìŒì„± OFF'}
        </button>
        
        <button
          onClick={() => setVoiceAnalysisEnabled(!voiceAnalysisEnabled)}
          className={`btn-voice-analysis ${voiceAnalysisEnabled ? 'analysis-on' : 'analysis-off'}`}
        >
          {voiceAnalysisEnabled ? <Mic /> : <MicOff />}
          {voiceAnalysisEnabled ? ' ìŒì„±ë¶„ì„ ON' : ' ìŒì„±ë¶„ì„ OFF'}
        </button>
        
        {voiceAnalysisReport && (
          <button onClick={() => setShowVoiceReport(true)} className="btn-voice-report">
            <BarChart />
            ìŒì„± ë¶„ì„ ê²°ê³¼
          </button>
        )}
        
        {!interviewData.active && (
          <button
            onClick={forceCheckVoiceReport}
            style={{
              background: 'linear-gradient(135deg, #ff6b6b, #ee5a24)',
              color: 'white',
              border: 'none',
              padding: '12px 20px',
              borderRadius: '8px',
              cursor: 'pointer',
              fontSize: '14px',
              fontWeight: 'bold',
              boxShadow: '0 4px 12px rgba(255, 107, 107, 0.3)'
            }}
          >
            ë¦¬í¬íŠ¸ í™•ì¸
          </button>
        )}
      </div>

      {isAnalyzing && !interviewData.active && (
        <div className="interview-guide">
          <h3>ë©´ì ‘ ì—°ìŠµ ê°€ì´ë“œ (WebRTC ë°©ì‹)</h3>
          <div className="guide-content">
            <div className="guide-item">
              <span className="guide-icon">ğŸ“¹</span>
              <span><strong>WebRTC</strong>ë¡œ ë¸Œë¼ìš°ì € ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ’­</span>
              <span>ì§ˆë¬¸ í›„ <strong>10ì´ˆ ìƒê° ì‹œê°„</strong>ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ—£ï¸</span>
              <span><strong>60ì´ˆ ë‹µë³€ ì‹œê°„</strong> ë™ì•ˆ ììœ ë¡­ê²Œ ë‹µë³€í•˜ì„¸ìš”</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ¤</span>
              <span><strong>AI ìŒì„± ë¶„ì„</strong>ìœ¼ë¡œ ì¶”ì„ìƒˆì™€ ë°œìŒì„ ë¶„ì„í•©ë‹ˆë‹¤</span>
            </div>
          </div>
        </div>
      )}
      
      {showVoiceReport && voiceAnalysisReport && (
        <VoiceAnalysisReport 
          report={voiceAnalysisReport} 
          show={showVoiceReport} 
          onClose={() => setShowVoiceReport(false)} 
        />
      )}
    </div>
  );
}

// ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ì»´í¬ë„ŒíŠ¸
function VoiceAnalysisReport({ report, show, onClose }) {
  if (!report || !show) return null;
  
  const hasAI = report.ai_powered;
  const aiDetails = report.ai_details;
  const details = report.detailed_analysis;

  // ë‹«ê¸° í•¸ë“¤ëŸ¬
  const handleClose = (e) => {
    e.stopPropagation();
    console.log('ë¦¬í¬íŠ¸ ë‹«ê¸°');
    onClose();
  };

  // ë°°ê²½ í´ë¦­ í•¸ë“¤ëŸ¬
  const handleBackgroundClick = (e) => {
    if (e.target === e.currentTarget) {
      console.log('ë¦¬í¬íŠ¸ ë°°ê²½ í´ë¦­ - ë‹«ê¸°');
      onClose();
    }
  };

  return (
    <div 
      style={{
        position: 'fixed',
        top: 0,
        left: 0,
        right: 0,
        bottom: 0,
        background: 'rgba(0, 0, 0, 0.8)',
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'center',
        zIndex: 10000,
        padding: '20px'
      }}
      onClick={handleBackgroundClick}
    >
      <div 
        style={{
          background: 'white',
          borderRadius: '16px',
          maxWidth: '800px',
          width: '100%',
          maxHeight: '90vh',
          overflow: 'auto',
          boxShadow: '0 20px 60px rgba(0,0,0,0.3)'
        }}
        onClick={(e) => e.stopPropagation()}
      >
        <div style={{
          padding: '20px 30px',
          borderBottom: '1px solid #eee',
          display: 'flex',
          justifyContent: 'space-between',
          alignItems: 'center',
          position: 'sticky',
          top: 0,
          background: 'white',
          zIndex: 1
        }}>
          <h2 style={{ margin: 0, fontSize: '24px', fontWeight: 'bold' }}>
            ìŒì„± ë¶„ì„ ê²°ê³¼ {hasAI && <span style={{fontSize: '14px', color: '#4CAF50', marginLeft: '8px'}}>AI ë¶„ì„</span>}
          </h2>
          <button 
            onClick={handleClose}
            style={{
              background: 'none',
              border: 'none',
              fontSize: '28px',
              cursor: 'pointer',
              color: '#999',
              padding: '0',
              lineHeight: 1,
              width: '40px',
              height: '40px',
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center',
              borderRadius: '50%',
              transition: 'background 0.2s'
            }}
            onMouseEnter={(e) => e.target.style.background = '#f0f0f0'}
            onMouseLeave={(e) => e.target.style.background = 'none'}
          >
            âœ•
          </button>
        </div>
        
        <div style={{ padding: '30px' }}>
          <div style={{ textAlign: 'center', marginBottom: '30px' }}>
            <div style={{
              display: 'inline-flex',
              width: '120px',
              height: '120px',
              borderRadius: '50%',
              background: report.overall_score >= 80 ? '#4CAF50' : 
                         report.overall_score >= 60 ? '#FFC107' : '#F44336',
              color: 'white',
              flexDirection: 'column',
              alignItems: 'center',
              justifyContent: 'center',
              boxShadow: '0 8px 24px rgba(0,0,0,0.15)'
            }}>
              <span style={{ fontSize: '48px', fontWeight: 'bold', lineHeight: 1 }}>{report.overall_score}</span>
              <span style={{ fontSize: '14px', marginTop: '8px', opacity: 0.9 }}>ì¢…í•© ì ìˆ˜</span>
            </div>
          </div>
          
          <div style={{ marginBottom: '30px' }}>
            <MetricBar label="ìŒì„± ìì‹ ê°" value={details.voice_confidence} />
            <MetricBar label="ìŒëŸ‰ ì¼ê´€ì„±" value={details.volume_consistency} />
            <MetricBar label="ìŒì„± ì•ˆì •ì„±" value={details.voice_stability} />
            
            {hasAI && details.jitter_percent !== undefined && (
              <MetricBar 
                label="ìŒì • ë–¨ë¦¼" 
                value={Math.max(0, 100 - details.jitter_percent * 20)}
                rawValue={`${details.jitter_percent.toFixed(2)}%`}
                color={details.jitter_percent < 2 ? '#4CAF50' : details.jitter_percent < 3.5 ? '#FFC107' : '#F44336'}
              />
            )}
            
            {hasAI && details.average_pitch !== undefined && (
              <MetricBar 
                label="í‰ê·  ìŒë†’ì´" 
                value={70}
                rawValue={`${details.average_pitch.toFixed(0)} Hz`}
                color="#2196F3"
              />
            )}
            
            {hasAI && details.vocabulary_richness !== undefined && (
              <MetricBar 
                label="ì–´íœ˜ ë‹¤ì–‘ì„±" 
                value={details.vocabulary_richness}
              />
            )}
          </div>
          
          <div style={{
            display: 'grid',
            gridTemplateColumns: 'repeat(auto-fit, minmax(180px, 1fr))',
            gap: '15px',
            marginBottom: '25px',
            padding: '20px',
            background: '#f9f9f9',
            borderRadius: '12px'
          }}>
            <StatItem label="ë§í•˜ê¸° ì‹œê°„" value={`${details.total_speaking_time}ì´ˆ`} />
            <StatItem label="ì¶”ì„ìƒˆ ì‚¬ìš©" value={`${details.filler_word_count}íšŒ (${details.filler_ratio}%)`} />
            {hasAI && details.connective_count !== undefined && (
              <StatItem label="ì ‘ì†ì‚¬ ì‚¬ìš©" value={`${details.connective_count}íšŒ`} />
            )}
            {hasAI && details.avg_sentence_length !== undefined && (
              <StatItem label="í‰ê·  ë¬¸ì¥ ê¸¸ì´" value={`${details.avg_sentence_length.toFixed(1)}ë‹¨ì–´`} />
            )}
          </div>
          
          {hasAI && aiDetails && aiDetails.recognized_text && (
            <div style={{
              background: '#f5f5f5',
              padding: '20px',
              borderRadius: '12px',
              marginBottom: '20px',
              maxHeight: '200px',
              overflow: 'auto',
              border: '1px solid #e0e0e0'
            }}>
              <h4 style={{margin: '0 0 12px 0', fontSize: '15px', color: '#666', fontWeight: '600'}}>
                Whisper ì¸ì‹ í…ìŠ¤íŠ¸:
              </h4>
              <p style={{margin: 0, fontSize: '14px', lineHeight: '1.8', color: '#333'}}>
                {aiDetails.recognized_text}
              </p>
            </div>
          )}
          
          {hasAI && aiDetails && (
            <div style={{
              background: 'linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%)',
              padding: '20px',
              borderRadius: '12px',
              marginBottom: '20px',
              border: '1px solid #90caf9'
            }}>
              <h4 style={{margin: '0 0 15px 0', fontSize: '16px', color: '#1976D2', fontWeight: 'bold'}}>
                AI ìƒì„¸ ë¶„ì„
              </h4>
              
              {aiDetails.filler_words && Object.keys(aiDetails.filler_words).length > 0 && (
                <DetailSection title="ì¶”ì„ìƒˆ ë¶„ì„" items={aiDetails.filler_words} />
              )}
              
              {aiDetails.connectives && Object.keys(aiDetails.connectives).length > 0 && (
                <DetailSection title="ì ‘ì†ì‚¬ ë¶„ì„" items={aiDetails.connectives} />
              )}
              
              {aiDetails.top_nouns && Object.keys(aiDetails.top_nouns).length > 0 && (
                <DetailSection 
                  title="ìì£¼ ì‚¬ìš©í•œ ë‹¨ì–´" 
                  items={Object.fromEntries(Object.entries(aiDetails.top_nouns).slice(0, 8))} 
                />
              )}
            </div>
          )}
          
          <div style={{
            background: '#fff3e0',
            padding: '20px',
            borderRadius: '12px',
            border: '1px solid #ffb74d'
          }}>
            <h3 style={{ fontSize: '18px', marginBottom: '15px', color: '#f57c00', fontWeight: 'bold' }}>
              ê°œì„  ì œì•ˆ
            </h3>
            <ul style={{ margin: 0, padding: '0 0 0 20px' }}>
              {report.recommendations.map((rec, index) => (
                <li key={index} style={{ 
                  marginBottom: '10px', 
                  lineHeight: '1.6',
                  fontSize: '14px',
                  color: '#424242'
                }}>
                  {rec}
                </li>
              ))}
            </ul>
          </div>
          
          {report.debug_info && (
            <div style={{
              fontSize: '11px',
              color: '#999',
              marginTop: '20px',
              padding: '12px',
              background: '#fafafa',
              borderRadius: '8px',
              border: '1px solid #eee'
            }}>
              <div>ë¶„ì„ ìƒ˜í”Œ: {report.debug_info.samples_analyzed}ê°œ</div>
              <div>ì²­í¬ ìˆ˜ì‹ : {report.debug_info.chunks_received}ê°œ</div>
              {hasAI && (
                <>
                  <div>Whisper: {report.debug_info.has_whisper ? 'í™œì„±' : 'ë¹„í™œì„±'}</div>
                  <div>librosa: {report.debug_info.has_librosa ? 'í™œì„±' : 'ë¹„í™œì„±'}</div>
                </>
              )}
            </div>
          )}
        </div>
      </div>
    </div>
  );
}

function MetricBar({ label, value, rawValue, color = '#4CAF50' }) {
  return (
    <div style={{ marginBottom: '18px' }}>
      <div style={{ 
        display: 'flex', 
        justifyContent: 'space-between', 
        alignItems: 'center',
        marginBottom: '6px'
      }}>
        <span style={{ fontSize: '14px', fontWeight: '500', color: '#555' }}>{label}</span>
        <span style={{ fontSize: '13px', fontWeight: 'bold', color: '#333' }}>
          {rawValue || `${value}%`}
        </span>
      </div>
      <div style={{ 
        background: '#eee', 
        height: '10px', 
        borderRadius: '5px', 
        overflow: 'hidden',
        boxShadow: 'inset 0 1px 3px rgba(0,0,0,0.1)'
      }}>
        <div style={{ 
          width: `${value}%`, 
          height: '100%', 
          background: color,
          transition: 'width 0.5s ease',
          borderRadius: '5px'
        }}></div>
      </div>
    </div>
  );
}

function StatItem({ label, value }) {
  return (
    <div>
      <div style={{ fontSize: '12px', color: '#888', marginBottom: '4px' }}>{label}</div>
      <div style={{ fontSize: '18px', fontWeight: 'bold', color: '#333' }}>{value}</div>
    </div>
  );
}

function DetailSection({ title, items }) {
  return (
    <div style={{ marginBottom: '15px' }}>
      <strong style={{ fontSize: '14px', display: 'block', marginBottom: '8px', color: '#555' }}>
        {title}:
      </strong>
      <div style={{ fontSize: '13px' }}>
        {Object.entries(items).map(([word, count]) => (
          <span key={word} style={{
            display: 'inline-block',
            background: 'white',
            padding: '5px 12px',
            borderRadius: '16px',
            margin: '4px',
            border: '1px solid #ddd',
            boxShadow: '0 1px 3px rgba(0,0,0,0.05)'
          }}>
            "{word}" <strong>{count}íšŒ</strong>
          </span>
        ))}
      </div>
    </div>
  );
}