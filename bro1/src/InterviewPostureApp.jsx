// App.jsx - MediaRecorder ê¸°ë°˜ ìì„¸ ë¶„ì„ + ìŒì„± ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ (ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ í¬í•¨)
import React, { useState, useEffect, useRef } from 'react';
import '../src/interview.css';

const BASE_URL = 'http://192.168.0.6:5001';

// SVG ì•„ì´ì½˜ë“¤
const Camera = () => (
  <svg width="64" height="64" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M23 19a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h4l2-3h6l2 3h4a2 2 0 0 1 2 2z" />
    <circle cx="12" cy="13" r="4" />
  </svg>
);

const AlertCircle = ({ className = "" }) => (
  <svg className={className} width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <circle cx="12" cy="12" r="10" />
    <line x1="12" y1="8" x2="12" y2="12" />
    <line x1="12" y1="16" x2="12.01" y2="16" />
  </svg>
);

const VolumeX = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5" />
    <line x1="23" y1="9" x2="17" y2="15" />
    <line x1="17" y1="9" x2="23" y2="15" />
  </svg>
);

const Volume2 = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5" />
    <path d="M19.07 4.93a10 10 0 0 1 0 14.14M15.54 8.46a5 5 0 0 1 0 7.07" />
  </svg>
);

const MessageSquare = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z" />
  </svg>
);

const Brain = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M12 2a3 3 0 0 0-3 3 4 4 0 0 0-4 4v6a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V9a4 4 0 0 0-4-4 3 3 0 0 0-3-3z" />
    <path d="M12 9v4" />
    <path d="M12 17v.01" />
  </svg>
);

const Mic = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3z" />
    <path d="M19 10v2a7 7 0 0 1-14 0v-2" />
    <line x1="12" y1="19" x2="12" y2="23" />
    <line x1="8" y1="23" x2="16" y2="23" />
  </svg>
);

const MicOff = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <line x1="1" y1="1" x2="23" y2="23" />
    <path d="M9 9v3a3 3 0 0 0 5.12 2.12" />
    <path d="M15 9.34V5a3 3 0 0 0-5.94-.6" />
    <path d="M17 16.95A7 7 0 0 1 5 12v-2" />
    <path d="M19 10v2a7 7 0 0 1-.11 1.23" />
    <line x1="12" y1="19" x2="12" y2="23" />
    <line x1="8" y1="23" x2="16" y2="23" />
  </svg>
);

const BarChart = () => (
  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2">
    <line x1="12" y1="20" x2="12" y2="10" />
    <line x1="18" y1="20" x2="18" y2="4" />
    <line x1="6" y1="20" x2="6" y2="16" />
  </svg>
);

export default function InterviewPostureVoiceApp() {
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [isServerConnected, setIsServerConnected] = useState(false);
  const [videoError, setVideoError] = useState(false);
  const [realtimeData, setRealtimeData] = useState(null);
  const [currentIssues, setCurrentIssues] = useState([]);
  const [postureScore, setPostureScore] = useState(100);
  const [isOverlayMode, setIsOverlayMode] = useState(false);
  const [deviceInfo, setDeviceInfo] = useState({
    isMobile: false,
    isTablet: false,
    orientation: 'portrait'
  });
  
  // ìŒì„± ê´€ë ¨ ìƒíƒœ
  const [voiceEnabled, setVoiceEnabled] = useState(true);
  const [voiceAnalysisEnabled, setVoiceAnalysisEnabled] = useState(true);
  const [voiceAnalysisActive, setVoiceAnalysisActive] = useState(false);
  const [voiceLevel, setVoiceLevel] = useState(0);
  const [voiceAnalysisReport, setVoiceAnalysisReport] = useState(null);
  const [showVoiceReport, setShowVoiceReport] = useState(false);
  
  // ğŸ”§ ì¶”ê°€: ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ìƒíƒœ
  const [micTestActive, setMicTestActive] = useState(false);
  const [micTestResults, setMicTestResults] = useState(null);
  
  // ë©´ì ‘ ê´€ë ¨ ìƒíƒœ
  const [interviewData, setInterviewData] = useState({
    active: false,
    current_question: null,
    category: null,
    question_number: 0,
    total_questions: 0,
    phase: 'thinking',
    time_remaining: 0,
    current_stage: null
  });
  
  const imgRef = useRef(null);
  const eventSourceRef = useRef(null);
  const lastSpokenIssueRef = useRef('');
  const lastIssueTimeRef = useRef({});
  const lastQuestionRef = useRef('');
  
  // MediaRecorder ê´€ë ¨ refs
  const mediaRecorderRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const speechRecognitionRef = useRef(null);
  const chunkCountRef = useRef(0);
  const voiceLevelIntervalRef = useRef(null);
  
  // ğŸ”§ ì¶”ê°€: ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ê´€ë ¨ refs
  const micTestIntervalRef = useRef(null);
  const micTestAudioContextRef = useRef(null);

  // Web Speech API ì´ˆê¸°í™”
  const initSpeechSynthesis = () => {
    if ('speechSynthesis' in window) {
      const loadVoices = () => {
        const voices = speechSynthesis.getVoices();
    
        return voices;
      };

      if (speechSynthesis.getVoices().length === 0) {
        speechSynthesis.addEventListener('voiceschanged', loadVoices, { once: true });
      }
      
      return true;
    }
    console.warn('âŒ Web Speech APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
    return false;
  };

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  const initSpeechRecognition = () => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      console.warn('âŒ Speech Recognition APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
      return false;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'ko-KR';
    
    let finalTranscript = '';
    
    recognition.onresult = (event) => {
      let interimTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        
        if (event.results[i].isFinal) {
          finalTranscript += transcript + ' ';
          sendSpeechTextToServer(transcript.trim());
        } else {
          interimTranscript += transcript;
        }
      }
    };
    
    recognition.onerror = (event) => {
      console.error('ìŒì„± ì¸ì‹ ì˜¤ë¥˜:', event.error);
      if (event.error === 'not-allowed') {
        alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.');
      }
    };
    
    recognition.onend = () => {
      if (voiceAnalysisActive && interviewData.active) {
        setTimeout(() => {
          try {
            recognition.start();
          } catch (e) {
            console.warn('ìŒì„± ì¸ì‹ ì¬ì‹œì‘ ì‹¤íŒ¨:', e);
          }
        }, 100);
      }
    };
    
    speechRecognitionRef.current = recognition;
    return true;
  };

  // ğŸ”§ ìƒˆë¡œìš´: ì¢…í•© ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
  const runMicrophoneTest = async () => {
    try {
      console.log('ğŸ§ª ì¢…í•© ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...');
      setMicTestActive(true);
      setMicTestResults(null);
      
      // 1. ê¸°ë³¸ ê¶Œí•œ ë° ë””ë°”ì´ìŠ¤ í™•ì¸
      console.log('1ï¸âƒ£ ë§ˆì´í¬ ê¶Œí•œ ë° ë””ë°”ì´ìŠ¤ í™•ì¸...');
      
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioDevices = devices.filter(device => device.kind === 'audioinput');
      console.log('ğŸ¤ ë°œê²¬ëœ ì˜¤ë””ì˜¤ ì…ë ¥ ì¥ì¹˜:', audioDevices);
      
      if (audioDevices.length === 0) {
        throw new Error('ë§ˆì´í¬ ë””ë°”ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
      
      // 2. ìŠ¤íŠ¸ë¦¼ íšë“ í…ŒìŠ¤íŠ¸
      console.log('2ï¸âƒ£ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“ í…ŒìŠ¤íŠ¸...');
      
      const constraints = {
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100,
          channelCount: 1
        }
      };
      
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      const audioTrack = stream.getAudioTracks()[0];
      
      console.log('ğŸ“Š ì˜¤ë””ì˜¤ íŠ¸ë™ ì •ë³´:', {
        label: audioTrack.label,
        enabled: audioTrack.enabled,
        muted: audioTrack.muted,
        readyState: audioTrack.readyState,
        settings: audioTrack.getSettings()
      });
      
      // 3. AudioContext í…ŒìŠ¤íŠ¸
      console.log('3ï¸âƒ£ AudioContext ì‹¤ì‹œê°„ ë¶„ì„ í…ŒìŠ¤íŠ¸...');
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      console.log('ğŸ›ï¸ AudioContext ìƒíƒœ:', audioContext.state);
      
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
        console.log('ğŸ”„ AudioContext í™œì„±í™” ì™„ë£Œ');
      }
      
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 2048;
      analyser.smoothingTimeConstant = 0.8;
      source.connect(analyser);
      
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      const timeDataArray = new Float32Array(analyser.fftSize);
      
      micTestAudioContextRef.current = audioContext;
      
      // 4. ì‹¤ì‹œê°„ ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ (10ì´ˆê°„)
      console.log('4ï¸âƒ£ 10ì´ˆê°„ ì‹¤ì‹œê°„ ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§...');
      console.log('ğŸ—£ï¸ ì§€ê¸ˆ ë§ˆì´í¬ì— ë§í•´ë³´ì„¸ìš”!');
      
      let testCount = 0;
      let maxVolume = 0;
      let avgVolume = 0;
      let volumeSum = 0;
      let signalCount = 0;
      const testDuration = 10000; // 10ì´ˆ
      const intervalMs = 100;
      const maxCount = testDuration / intervalMs;
      
      const testResults = {
        maxVolume: 0,
        avgVolume: 0,
        signalDetected: false,
        samples: [],
        deviceInfo: {
          audioDevices: audioDevices.length,
          deviceLabel: audioTrack.label,
          sampleRate: audioTrack.getSettings().sampleRate
        }
      };
      
      micTestIntervalRef.current = setInterval(() => {
        analyser.getByteFrequencyData(dataArray);
        analyser.getFloatTimeDomainData(timeDataArray);
        
        // ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ë³¼ë¥¨ ê³„ì‚°
        const freqSum = dataArray.reduce((a, b) => a + b, 0);
        const freqAvg = freqSum / bufferLength;
        const freqVolume = (freqAvg / 128) * 100;
        
        // ì‹œê°„ ë„ë©”ì¸ ë³¼ë¥¨ ê³„ì‚° (RMS)
        const rms = Math.sqrt(timeDataArray.reduce((sum, val) => sum + val * val, 0) / timeDataArray.length);
        const rmsVolume = Math.min(100, rms * 1000);
        
        // ì‹ í˜¸ ê°ì§€
        const hasSignal = rms > 0.001 || freqAvg > 5;
        
        if (hasSignal) {
          signalCount++;
          testResults.signalDetected = true;
        }
        
        const currentVolume = Math.max(freqVolume, rmsVolume);
        maxVolume = Math.max(maxVolume, currentVolume);
        volumeSum += currentVolume;
        
        // ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸
        setVoiceLevel(currentVolume);
        
        // ìƒ˜í”Œ ì €ì¥
        testResults.samples.push({
          time: testCount * intervalMs,
          freqVolume,
          rmsVolume,
          hasSignal,
          freqAvg,
          rms: rms * 1000
        });
        
        if (testCount % 10 === 0) {
          console.log(`ğŸ”Š í…ŒìŠ¤íŠ¸ ${testCount}/${maxCount}: ì£¼íŒŒìˆ˜=${freqVolume.toFixed(1)}%, RMS=${rmsVolume.toFixed(1)}%, ì‹ í˜¸=${hasSignal ? 'âœ…' : 'âŒ'}`);
        }
        
        testCount++;
        
        if (testCount >= maxCount) {
          // í…ŒìŠ¤íŠ¸ ì™„ë£Œ
          clearInterval(micTestIntervalRef.current);
          
          testResults.maxVolume = maxVolume;
          testResults.avgVolume = volumeSum / testCount;
          testResults.signalRatio = (signalCount / testCount) * 100;
          
          console.log('ğŸ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ:', testResults);
          
          // ì •ë¦¬
          stream.getTracks().forEach(track => track.stop());
          audioContext.close();
          
          setMicTestActive(false);
          setMicTestResults(testResults);
          setVoiceLevel(0);
          
          // í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„
          analyzeMicTestResults(testResults);
        }
      }, intervalMs);
      
    } catch (error) {
      console.error('âŒ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error);
      setMicTestActive(false);
      setMicTestResults({ error: error.message });
      
      let errorMessage = 'ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:\n\n';
      
      if (error.name === 'NotAllowedError') {
        errorMessage += 'ğŸ”’ ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní•´ê²°ë°©ë²•:\n1. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ ì™¼ìª½ ìë¬¼ì‡  ì•„ì´ì½˜ í´ë¦­\n2. ë§ˆì´í¬ ê¶Œí•œì„ "í—ˆìš©"ìœ¼ë¡œ ë³€ê²½\n3. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨';
      } else if (error.name === 'NotFoundError') {
        errorMessage += 'ğŸ¤ ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\ní™•ì¸ì‚¬í•­:\n1. ë§ˆì´í¬ê°€ ì»´í“¨í„°ì— ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€\n2. ë‹¤ë¥¸ ì•±ì—ì„œ ë§ˆì´í¬ë¥¼ ì‚¬ìš© ì¤‘ì¸ì§€\n3. ì‹œìŠ¤í…œ ì‚¬ìš´ë“œ ì„¤ì • í™•ì¸';
      } else if (error.name === 'NotSupportedError') {
        errorMessage += 'ğŸš« ì´ ë¸Œë¼ìš°ì €ëŠ” ë§ˆì´í¬ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nChrome, Firefox, Safarië¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.';
      } else {
        errorMessage += `âŒ ${error.message}\n\në¸Œë¼ìš°ì € ì½˜ì†”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.`;
      }
      
      alert(errorMessage);
    }
  };

  // ğŸ”§ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„ í•¨ìˆ˜
  const analyzeMicTestResults = (results) => {
    if (results.error) {
      console.error('í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', results.error);
      return;
    }
    
    console.log('ğŸ“Š ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„:');
    console.log(`   ìµœëŒ€ ë³¼ë¥¨: ${results.maxVolume.toFixed(1)}%`);
    console.log(`   í‰ê·  ë³¼ë¥¨: ${results.avgVolume.toFixed(1)}%`);
    console.log(`   ì‹ í˜¸ ê°ì§€ìœ¨: ${results.signalRatio.toFixed(1)}%`);
    console.log(`   ì‹ í˜¸ ê°ì§€: ${results.signalDetected ? 'âœ…' : 'âŒ'}`);
    
    let diagnosis = 'ğŸ©º ë§ˆì´í¬ ì§„ë‹¨ ê²°ê³¼:\n\n';
    let recommendations = [];
    
    if (!results.signalDetected) {
      diagnosis += 'âŒ ë§ˆì´í¬ì—ì„œ ì‹ í˜¸ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n';
      recommendations.push('ë§ˆì´í¬ê°€ ìŒì†Œê±°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸');
      recommendations.push('ë§ˆì´í¬ì— ë§í•´ë³´ê¸°');
      recommendations.push('ë§ˆì´í¬ ë³¼ë¥¨ ì„¤ì • í™•ì¸');
      recommendations.push('ë‹¤ë¥¸ ì•±ì—ì„œ ë§ˆì´í¬ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸');
    } else if (results.maxVolume < 5) {
      diagnosis += 'âš ï¸ ë§ˆì´í¬ ë³¼ë¥¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\n';
      recommendations.push('ì‹œìŠ¤í…œ ë§ˆì´í¬ ë³¼ë¥¨ ì¦ê°€');
      recommendations.push('ë§ˆì´í¬ì— ë” ê°€ê¹Œì´ ë§í•˜ê¸°');
      recommendations.push('ì£¼ë³€ ì†ŒìŒ í™•ì¸');
    } else if (results.maxVolume < 20) {
      diagnosis += 'ğŸ“ˆ ë§ˆì´í¬ ë³¼ë¥¨ì´ ë‚®ìŠµë‹ˆë‹¤.\n';
      recommendations.push('ì¢€ ë” í¬ê²Œ ë§í•´ë³´ê¸°');
      recommendations.push('ë§ˆì´í¬ì™€ì˜ ê±°ë¦¬ ì¡°ì ˆ');
    } else if (results.maxVolume > 80) {
      diagnosis += 'ğŸ”Š ë§ˆì´í¬ ë³¼ë¥¨ì´ ë†’ìŠµë‹ˆë‹¤.\n';
      recommendations.push('ë§ˆì´í¬ ë³¼ë¥¨ì„ ì¡°ê¸ˆ ë‚®ì¶°ë³´ì„¸ìš”');
      recommendations.push('ë§ˆì´í¬ì™€ì˜ ê±°ë¦¬ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”');
    } else {
      diagnosis += 'âœ… ë§ˆì´í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!\n';
      recommendations.push('ë©´ì ‘ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤');
    }
    
    // ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶”ê°€
    diagnosis += `\nğŸ“± ë””ë°”ì´ìŠ¤ ì •ë³´:\n`;
    diagnosis += `   ê°ì§€ëœ ë§ˆì´í¬: ${results.deviceInfo.audioDevices}ê°œ\n`;
    diagnosis += `   ì‚¬ìš© ì¤‘ì¸ ë§ˆì´í¬: ${results.deviceInfo.deviceLabel}\n`;
    diagnosis += `   ìƒ˜í”Œë ˆì´íŠ¸: ${results.deviceInfo.sampleRate}Hz\n`;
    
    if (recommendations.length > 0) {
      diagnosis += '\nğŸ’¡ ê¶Œì¥ì‚¬í•­:\n';
      recommendations.forEach((rec, idx) => {
        diagnosis += `${idx + 1}. ${rec}\n`;
      });
    }
    
    alert(diagnosis);
  };

  // ğŸ”§ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì¤‘ì§€ í•¨ìˆ˜
  const stopMicTest = () => {
    if (micTestIntervalRef.current) {
      clearInterval(micTestIntervalRef.current);
      micTestIntervalRef.current = null;
    }
    
    if (micTestAudioContextRef.current) {
      micTestAudioContextRef.current.close();
      micTestAudioContextRef.current = null;
    }
    
    setMicTestActive(false);
    setVoiceLevel(0);
    console.log('ğŸ›‘ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì¤‘ì§€ë¨');
  };

  // playBeep í•¨ìˆ˜ë¥¼ stopMicTest() í•¨ìˆ˜ ì•„ë˜ì— ì¶”ê°€
const playBeep = () => {
    try {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const oscillator = audioContext.createOscillator();
      const gainNode = audioContext.createGain();
      
      oscillator.connect(gainNode);
      gainNode.connect(audioContext.destination);
      
      oscillator.frequency.value = 800;
      oscillator.type = 'sine';
      
      gainNode.gain.setValueAtTime(0.3, audioContext.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3);
      
      oscillator.start(audioContext.currentTime);
      oscillator.stop(audioContext.currentTime + 0.3);
      
      console.log('ğŸ”” ë‹µë³€ ì‹œì‘ ì‹ í˜¸ìŒ');
    } catch (error) {
      console.error('ì‹ í˜¸ìŒ ì¬ìƒ ì‹¤íŒ¨:', error);
    }
  };

  // MediaRecorder ì´ˆê¸°í™”
  const initMediaRecorderAnalysis = async () => {
    try {
      console.log('ğŸ¤ MediaRecorder ì´ˆê¸°í™” ì‹œì‘...');
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      console.log('âœ… ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íšë“ ì„±ê³µ');
      console.log('ğŸ“Š ìŠ¤íŠ¸ë¦¼ ì •ë³´:', {
        tracks: stream.getAudioTracks().length,
        active: stream.active,
        settings: stream.getAudioTracks()[0]?.getSettings()
      });
      
      // ğŸ”§ ì¶”ê°€: ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒíƒœ í™•ì¸
      const audioTrack = stream.getAudioTracks()[0];
      if (audioTrack) {
        console.log('ğŸµ ì˜¤ë””ì˜¤ íŠ¸ë™ ìƒíƒœ:', {
          enabled: audioTrack.enabled,
          muted: audioTrack.muted,
          readyState: audioTrack.readyState,
          label: audioTrack.label
        });
        
        // íŠ¸ë™ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
        audioTrack.onended = () => console.log('ğŸ›‘ ì˜¤ë””ì˜¤ íŠ¸ë™ ì¢…ë£Œë¨');
        audioTrack.onmute = () => console.log('ğŸ”‡ ì˜¤ë””ì˜¤ íŠ¸ë™ ìŒì†Œê±°ë¨');
        audioTrack.onunmute = () => console.log('ğŸ”Š ì˜¤ë””ì˜¤ íŠ¸ë™ ìŒì†Œê±° í•´ì œë¨');
      }
      
      mediaStreamRef.current = stream;
      
      // MediaRecorder ì„¤ì •
      let mimeType = 'audio/webm;codecs=opus';
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        mimeType = 'audio/webm';
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = 'audio/mp4';
          if (!MediaRecorder.isTypeSupported(mimeType)) {
            mimeType = 'audio/wav';
          }
        }
      }
      
      console.log('ğŸµ ì‚¬ìš©í•  ì˜¤ë””ì˜¤ í˜•ì‹:', mimeType);
      
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: mimeType,
        audioBitsPerSecond: 128000
      });
      
      let audioChunks = [];
      chunkCountRef.current = 0;
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunkCountRef.current++;
          console.log(`ğŸ“¦ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  #${chunkCountRef.current} - í¬ê¸°: ${event.data.size} bytes`);
          
          audioChunks.push(event.data);
          
          // ğŸ”§ ìˆ˜ì •: ì¦‰ì‹œ ì „ì†¡ (ìƒíƒœ ì²´í¬ ì „ì—)
          // MediaRecorderê°€ í™œì„± ìƒíƒœì¼ ë•Œë§Œ ìƒì„±ë˜ë¯€ë¡œ ì•ˆì „í•¨
          sendAudioChunkToServer(event.data, chunkCountRef.current).catch(err => {
            console.error(`âŒ ì²­í¬ #${chunkCountRef.current} ì „ì†¡ ì‹¤íŒ¨:`, err);
          });
        } else {
          console.warn(`âš ï¸ ë¹ˆ ì²­í¬ ê°ì§€ #${chunkCountRef.current}`);
        }
      };
      
      mediaRecorder.onstop = () => {
        console.log(`ğŸ›‘ MediaRecorder ì¤‘ì§€ - ì´ ${chunkCountRef.current}ê°œ ì²­í¬ ìˆ˜ì§‘`);
        const audioBlob = new Blob(audioChunks, { type: mimeType });
        console.log('ğŸ“Š ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸°:', audioBlob.size, 'bytes');
        
        sendFinalAudioToServer(audioBlob);
        audioChunks = [];
        chunkCountRef.current = 0;
      };
      
      mediaRecorder.onerror = (event) => {
        console.error('âŒ MediaRecorder ì˜¤ë¥˜:', event.error);
      };
      
      mediaRecorderRef.current = mediaRecorder;
      
      console.log('ğŸ‰ MediaRecorder ì´ˆê¸°í™” ì™„ë£Œ!');
      return true;
      
    } catch (error) {
      console.error('âŒ MediaRecorder ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      
      let errorMessage = '';
      
      if (error.name === 'NotAllowedError') {
        errorMessage = `ğŸ”’ ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní•´ê²° ë°©ë²•:\n1. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ ì™¼ìª½ ğŸ”’ ì•„ì´ì½˜ í´ë¦­\n2. ë§ˆì´í¬ ê¶Œí•œì„ "í—ˆìš©"ìœ¼ë¡œ ë³€ê²½\n3. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨`;
      } else if (error.name === 'NotFoundError') {
        errorMessage = 'ğŸ¤ ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.';
      } else if (error.name === 'NotSupportedError') {
        errorMessage = 'ğŸš« MediaRecorderë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤. Chrome, Firefox, Safarië¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.';
      } else {
        errorMessage = `âŒ ë§ˆì´í¬ ì˜¤ë¥˜: ${error.message}`;
      }
      
      alert(errorMessage);
      return false;
    }
  };

// ğŸ”§ ìƒˆë¡œìš´: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì¶”ê°€
const initRealTimeAudioAnalyzer = async () => {
    if (!mediaStreamRef.current) {
      console.error('âŒ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ì´ ì—†ìŠµë‹ˆë‹¤.');
      return false;
    }
    
    try {
      console.log('ğŸ›ï¸ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘...');
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      console.log('ğŸ“Š AudioContext ìƒì„±:', audioContext.state);
      
      // AudioContextê°€ suspended ìƒíƒœë©´ resume
      if (audioContext.state === 'suspended') {
        await audioContext.resume();
        console.log('ğŸ”„ AudioContext resume ì™„ë£Œ:', audioContext.state);
      }
      
      const analyser = audioContext.createAnalyser();
      const source = audioContext.createMediaStreamSource(mediaStreamRef.current);
      
      analyser.fftSize = 256;
      analyser.smoothingTimeConstant = 0.8;
      source.connect(analyser);
      
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      
      console.log('âœ… ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì„¤ì • ì™„ë£Œ - ë²„í¼ í¬ê¸°:', bufferLength);
      
      let frameCount = 0;
      
      const updateVolume = () => {
        // voiceAnalysisActive ì²´í¬ë¥¼ ì œê±°í•˜ê³  í•­ìƒ ì‹¤í–‰
        analyser.getByteFrequencyData(dataArray);
        
        // ë³¼ë¥¨ ê³„ì‚°
        const sum = dataArray.reduce((a, b) => a + b, 0);
        const average = sum / bufferLength;
        const volume = Math.min(100, (average / 128) * 100);
        
        setVoiceLevel(volume);
        
        frameCount++;
        
        // ë¡œê·¸ (ë§¤ 100í”„ë ˆì„ë§ˆë‹¤, ì•½ 1.6ì´ˆ)
        if (frameCount % 100 === 0) {
          console.log(`ğŸ”Š ì‹¤ì‹œê°„ ë³¼ë¥¨: ${volume.toFixed(1)}% (í‰ê· : ${average.toFixed(1)}, í•©ê³„: ${sum})`);
        }
        
        // ê³„ì† ì‹¤í–‰
        requestAnimationFrame(updateVolume);
      };
      
      updateVolume();
      console.log('ğŸ¤ ì‹¤ì‹œê°„ ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ ì‹œì‘!');
      
      // ì •ë¦¬ìš©ìœ¼ë¡œ ì €ì¥
      voiceLevelIntervalRef.current = audioContext;
      
      return true;
      
    } catch (error) {
      console.error('âŒ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨:', error);
      return false;
    }
  };


  const stopVoiceLevelSimulation = () => {
    if (voiceLevelIntervalRef.current) {
      // AudioContextì¸ ê²½ìš° close, intervalì¸ ê²½ìš° clear
      if (typeof voiceLevelIntervalRef.current.close === 'function') {
        voiceLevelIntervalRef.current.close();
      } else {
        clearInterval(voiceLevelIntervalRef.current);
      }
      voiceLevelIntervalRef.current = null;
    }
    setVoiceLevel(0);
  };

  const sendAudioChunkToServer = async (audioBlob, chunkNumber) => {
    
    try {
      const formData = new FormData();
      formData.append('audio', audioBlob);
      formData.append('chunk_number', chunkNumber);
      formData.append('timestamp', Date.now());
      formData.append('question_number', interviewData.question_number || 0);
      formData.append('phase', interviewData.phase || 'unknown');
      
      console.log(`ğŸ“¤ ì²­í¬ #${chunkNumber} ì „ì†¡ ì¤‘... (${audioBlob.size} bytes)`);
      
      const response = await fetch(`${BASE_URL}/voice/audio_chunk_blob`, {
        method: 'POST',
        body: formData
      });
      
      if (response.ok) {
        const result = await response.json();
        console.log(`âœ… ì²­í¬ #${chunkNumber} ì „ì†¡ ì„±ê³µ:`, result);
      } else {
        console.error(`âŒ ì²­í¬ #${chunkNumber} ì „ì†¡ ì‹¤íŒ¨:`, response.status);
      }
      
    } catch (error) {
      console.error(`âŒ ì²­í¬ #${chunkNumber} ì „ì†¡ ì˜¤ë¥˜:`, error);
    }
  };

  // ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡
  const sendFinalAudioToServer = async (audioBlob) => {
    try {
      const formData = new FormData();
      formData.append('final_audio', audioBlob);
      formData.append('timestamp', Date.now());
      
      console.log('ğŸ“¤ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì¤‘...', audioBlob.size, 'bytes');
      
      const response = await fetch(`${BASE_URL}/voice/final_audio`, {
        method: 'POST',
        body: formData
      });
      
      if (response.ok) {
        console.log('âœ… ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì„±ê³µ');
      } else {
        console.error('âŒ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì‹¤íŒ¨:', response.status);
      }
      
    } catch (error) {
      console.error('âŒ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì†¡ ì˜¤ë¥˜:', error);
    }
  };

  // ì„œë²„ë¡œ ìŒì„± í…ìŠ¤íŠ¸ ì „ì†¡
  const sendSpeechTextToServer = async (text) => {
    if (!voiceAnalysisActive || !interviewData.active || !text.trim()) return;
    
    try {
      console.log('ğŸ“ ìŒì„± í…ìŠ¤íŠ¸ ì „ì†¡:', text);
      await fetch(`${BASE_URL}/voice/speech_text`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text: text.trim(),
          timestamp: Date.now(),
          question_number: interviewData.question_number,
          phase: interviewData.phase
        })
      });
    } catch (error) {
      console.error('ìŒì„± í…ìŠ¤íŠ¸ ì „ì†¡ ì‹¤íŒ¨:', error);
    }
  };

  // ìŒì„± ë¶„ì„ ì‹œì‘ í•¨ìˆ˜
  const startVoiceAnalysisSession = async () => {
    if (!voiceAnalysisEnabled) {
      console.log('âŒ ìŒì„± ë¶„ì„ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
      return false;
    }
    
    console.log('ğŸ¤ MediaRecorder ìŒì„± ë¶„ì„ ì„¸ì…˜ ì‹œì‘...');
    setVoiceAnalysisActive(true);
    
    // MediaRecorder ì´ˆê¸°í™”
    const success = await initMediaRecorderAnalysis();
    
    if (success && mediaRecorderRef.current) {
      try {
        // MediaRecorder ì‹œì‘
        mediaRecorderRef.current.start(100);
        console.log('âœ… MediaRecorder ë…¹ìŒ ì‹œì‘ (100ms ì²­í¬)');
        
        // ğŸ”§ ì¶”ê°€: ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì‹œì‘
        await initRealTimeAudioAnalyzer();
        
        // ìŒì„± ì¸ì‹ ì‹œì‘
        if (speechRecognitionRef.current) {
          speechRecognitionRef.current.start();
          console.log('âœ… ìŒì„± ì¸ì‹ ì‹œì‘');
        }
        
        return true;
      } catch (error) {
        console.error('âŒ MediaRecorder ì‹œì‘ ì‹¤íŒ¨:', error);
        setVoiceAnalysisActive(false);
        return false;
      }
    } else {
      console.error('âŒ MediaRecorder ì´ˆê¸°í™” ì‹¤íŒ¨');
      setVoiceAnalysisActive(false);
      return false;
    }
  };

  // ìŒì„± ë¶„ì„ ì¤‘ì§€
  const stopVoiceAnalysis = () => {
    console.log('ğŸ›‘ MediaRecorder ìŒì„± ë¶„ì„ ì¤‘ì§€ ì‹œì‘...');
    setVoiceAnalysisActive(false);
    
    // ë³¼ë¥¨ ë ˆë²¨ ì‹œë®¬ë ˆì´ì…˜ ì¤‘ì§€
    stopVoiceLevelSimulation();
    
    // MediaRecorder ì¤‘ì§€
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      try {
        mediaRecorderRef.current.stop();
        console.log('âœ… MediaRecorder ì¤‘ì§€ ì™„ë£Œ');
      } catch (error) {
        console.error('âŒ MediaRecorder ì¤‘ì§€ ì‹¤íŒ¨:', error);
      }
    }
    
    // ìŒì„± ì¸ì‹ ì¤‘ì§€
    if (speechRecognitionRef.current) {
      try {
        speechRecognitionRef.current.stop();
        console.log('âœ… ìŒì„± ì¸ì‹ ì¤‘ì§€ ì™„ë£Œ');
      } catch (error) {
        console.error('âŒ ìŒì„± ì¸ì‹ ì¤‘ì§€ ì‹¤íŒ¨:', error);
      }
    }
    
    // ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
      console.log('âœ… ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì™„ë£Œ');
    }
    
    // refs ì •ë¦¬
    mediaRecorderRef.current = null;
    
    console.log('ğŸ›‘ MediaRecorder ìŒì„± ë¶„ì„ ì™„ì „ ì¤‘ì§€');
  };

  // ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ê°€ì ¸ì˜¤ê¸°
  const fetchVoiceAnalysisReport = async () => {
    try {
      const response = await fetch(`${BASE_URL}/voice/analysis_report`);
      const data = await response.json();
      
      if (data.overall_score !== undefined) {
        setVoiceAnalysisReport(data);
        setShowVoiceReport(true);
        console.log('ğŸ“Š ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ìˆ˜ì‹ :', data);
      }
    } catch (error) {
      console.error('ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:', error);
    }
  };

  // TTS ìŒì„± ì¶œë ¥
  const speakQuestion = (text) => {
    if (!voiceEnabled || !text) return;
    if (lastQuestionRef.current === text) return;
    lastQuestionRef.current = text;

    if ('speechSynthesis' in window) {
      speechSynthesis.cancel();

      const utterance = new SpeechSynthesisUtterance(text);
      
      const voices = speechSynthesis.getVoices();
      const koreanVoice = voices.find(voice => 
        voice.lang.startsWith('ko') || 
        voice.name.includes('Korean') ||
        voice.name.includes('Kyoko') ||
        voice.name.includes('Yuna')
      );
      
      if (koreanVoice) {
        utterance.voice = koreanVoice;
      } else if (voices.length > 0) {
        utterance.voice = voices[0];
      }

      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      utterance.volume = 0.9;
      utterance.lang = 'ko-KR';

      utterance.onstart = () => console.log('ğŸ”Š ìŒì„± ì¶œë ¥ ì‹œì‘');
      utterance.onend = () => console.log('âœ… ìŒì„± ì¶œë ¥ ì™„ë£Œ');
      utterance.onerror = (event) => console.error('âŒ ìŒì„± ì¶œë ¥ ì˜¤ë¥˜:', event.error);

      speechSynthesis.speak(utterance);
    }
  };

  const stopSpeech = () => {
    if ('speechSynthesis' in window) {
      speechSynthesis.cancel();
      lastQuestionRef.current = '';
    }
  };

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì´ˆê¸°í™”
  useEffect(() => {
    console.log('ğŸš€ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘');
    initSpeechSynthesis();
    initSpeechRecognition();
    
    return () => {
      console.log('ğŸ§¹ ì»´í¬ë„ŒíŠ¸ ì •ë¦¬');
      stopSpeech();
      stopVoiceAnalysis();
      stopMicTest();
    };
  }, []);

  // ë””ë°”ì´ìŠ¤ ê°ì§€
  useEffect(() => {
    const updateDeviceInfo = () => {
      const width = window.innerWidth;
      const height = window.innerHeight;
      const isMobile = width <= 768;
      const isTablet = width > 768 && width <= 1024;
      const orientation = width > height ? 'landscape' : 'portrait';

      setDeviceInfo({ isMobile, isTablet, orientation, width, height });
    };

    updateDeviceInfo();
    window.addEventListener('resize', updateDeviceInfo);
    window.addEventListener('orientationchange', () => setTimeout(updateDeviceInfo, 100));

    return () => {
      window.removeEventListener('resize', updateDeviceInfo);
      window.removeEventListener('orientationchange', updateDeviceInfo);
    };
  }, []);

  // ìì„¸ í”¼ë“œë°± ìŒì„±
  const speakIssue = (text) => {
    if (!voiceEnabled || !text) return;
    
    const now = Date.now();
    if (lastIssueTimeRef.current[text]) {
      const timeSinceLastSpeak = now - lastIssueTimeRef.current[text];
      if (timeSinceLastSpeak < 5000) return;
    }
    
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ko-KR';
      utterance.rate = 1.1;
      utterance.pitch = 1.2;
      utterance.volume = 0.7;
      
      speechSynthesis.speak(utterance);
      lastIssueTimeRef.current[text] = now;
    }
  };

  // ì„œë²„ ì—°ê²° í™•ì¸
  useEffect(() => {
    const checkServer = async () => {
      try {
        const response = await fetch(`${BASE_URL}/health`);
        setIsServerConnected(response.ok);
      } catch (error) {
        setIsServerConnected(false);
      }
    };

    checkServer();
    const interval = setInterval(checkServer, 10000);
    return () => clearInterval(interval);
  }, []);

  // ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¼
  useEffect(() => {
    if (isAnalyzing && isServerConnected) {
        eventSourceRef.current = new EventSource(`${BASE_URL}/stream_data`);
        
        let previousPhase = ''; // ì¶”ê°€
        
        eventSourceRef.current.onmessage = (event) => {
          try {
            const data = JSON.parse(event.data);
            setRealtimeData(data);
            
            if (data.interview) {
              const prevQuestion = interviewData.current_question;
              const prevActive = interviewData.active;
              
              // phase ë³€ê²½ ê°ì§€ ì¶”ê°€
              if (previousPhase === 'thinking' && data.interview.phase === 'answering') {
                console.log('ğŸ”” ë‹µë³€ ì‹œì‘!');
                playBeep();
              }
              previousPhase = data.interview.phase;
              
              setInterviewData(data.interview);
            
            // ìƒˆë¡œìš´ ì§ˆë¬¸ ìŒì„± ì¶œë ¥
            if (data.interview.current_question && 
                data.interview.current_question !== prevQuestion &&
                data.interview.phase === 'thinking') {
              setTimeout(() => speakQuestion(data.interview.current_question), 500);
            }
            
            // ë©´ì ‘ì´ ë°©ê¸ˆ ëë‚¬ì„ ë•Œ ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ í™•ì¸
            if (prevActive && !data.interview.active && data.interview.phase === 'finished') {
              console.log('ğŸ¬ ë©´ì ‘ì´ ë°©ê¸ˆ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ í™•ì¸ ì¤‘...');
              setTimeout(() => {
                const checkReportInterval = setInterval(async () => {
                  try {
                    const response = await fetch(`${BASE_URL}/voice/analysis_report`);
                    const reportData = await response.json();
                    
                    if (reportData.overall_score !== undefined) {
                      console.log('ğŸ“Š ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ìˆ˜ì‹  ì™„ë£Œ:', reportData);
                      setVoiceAnalysisReport(reportData);
                      setShowVoiceReport(true);
                      stopVoiceAnalysis();
                      clearInterval(checkReportInterval);
                    } else {
                      console.log('â³ ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ëŒ€ê¸° ì¤‘...');
                    }
                  } catch (error) {
                    console.error('ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ í™•ì¸ ì‹¤íŒ¨:', error);
                  }
                }, 1000);
                
                setTimeout(() => {
                  clearInterval(checkReportInterval);
                  console.log('â° ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼');
                }, 10000);
                
              }, 2000);
            }
          }
          
          // ìŒì„± ë¶„ì„ ë°ì´í„° ì²˜ë¦¬
          if (data.voice_analysis) {
            console.log('ğŸ¤ ìŒì„± ë¶„ì„ ìƒíƒœ:', {
              active: data.voice_analysis.session_active,
              complete: data.voice_analysis.analysis_complete,
              hasData: data.voice_analysis.has_data,
              samples: data.voice_analysis.sample_count,
              fillers: data.voice_analysis.filler_count
            });
            
            if (data.voice_analysis.analysis_complete && 
                data.voice_analysis.final_report && 
                !voiceAnalysisReport) {
              console.log('ğŸ“Š ìŠ¤íŠ¸ë¦¼ì—ì„œ ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ìˆ˜ì‹ :', data.voice_analysis.final_report);
              setVoiceAnalysisReport(data.voice_analysis.final_report);
              setShowVoiceReport(true);
              stopVoiceAnalysis();
            }
          }
          
          // ìì„¸ ë¶„ì„ ë°ì´í„°
          if (data.issues && data.issues.length > 0) {
            setCurrentIssues(data.issues);
            if (!data.interview?.active) {
              data.issues.forEach((issue, index) => {
                setTimeout(() => speakIssue(issue), index * 100);
              });
            }
          } else {
            setCurrentIssues([]);
          }
          
          if (data.score !== undefined) {
            setPostureScore(data.score);
          }
        } catch (error) {
          console.error('ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜:', error);
        }
      };

      eventSourceRef.current.onerror = () => {
        eventSourceRef.current.close();
      };
    }

    return () => {
      if (eventSourceRef.current) {
        eventSourceRef.current.close();
      }
    };
  }, [isAnalyzing, isServerConnected, voiceEnabled, interviewData.current_question, interviewData.active, showVoiceReport]);

  // ë©´ì ‘ ì‹œì‘
  const startInterview = async () => {
    setVoiceAnalysisReport(null);
   setShowVoiceReport(false);
    try {
      console.log('ğŸ¬ ë©´ì ‘ ì‹œì‘ ìš”ì²­...');
      
      const response = await fetch(`${BASE_URL}/interview/start`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({})
      });
      
      if (response.ok) {
        const data = await response.json();
        console.log('âœ… ë©´ì ‘ ì‹œì‘ ì‘ë‹µ:', data);
        
        setInterviewData({
          active: true,
          current_question: data.current_question,
          category: data.category,
          question_number: 1,
          total_questions: data.total_questions,
          phase: 'thinking',
          time_remaining: 10,
          current_stage: data.flow_stage
        });

        // ìŒì„± ë¶„ì„ ì‹œì‘
        if (voiceAnalysisEnabled) {
          console.log('ğŸ¤ ìŒì„± ë¶„ì„ í™œì„±í™” ì‹œë„...');
          const voiceStarted = await startVoiceAnalysisSession();
          if (voiceStarted) {
            console.log('âœ… ìŒì„± ë¶„ì„ í™œì„±í™” ì„±ê³µ');
          } else {
            console.log('âŒ ìŒì„± ë¶„ì„ í™œì„±í™” ì‹¤íŒ¨');
          }
        }

        // ì²« ì§ˆë¬¸ ìŒì„± ì¶œë ¥
        setTimeout(() => speakQuestion(data.current_question), 1000);
        
      }
    } catch (error) {
      console.error('ë©´ì ‘ ì‹œì‘ ì‹¤íŒ¨:', error);
    }
  };

  // ë©´ì ‘ ì¤‘ì§€
  const stopInterview = async () => {
    try {
      console.log('ğŸ›‘ ë©´ì ‘ ì¤‘ì§€ ìš”ì²­...');
      await fetch(`${BASE_URL}/interview/stop`, { method: 'POST' });
      stopSpeech();
      stopVoiceAnalysis();
      
      setInterviewData({
        active: false,
        current_question: null,
        category: null,
        question_number: 0,
        total_questions: 0,
        phase: 'thinking',
        time_remaining: 0,
        current_stage: null
      });

      setTimeout(() => fetchVoiceAnalysisReport(), 2000);
      
    } catch (error) {
      console.error('ë©´ì ‘ ì¤‘ì§€ ì‹¤íŒ¨:', error);
    }
  };

  // ë¶„ì„ ì‹œì‘/ì¤‘ì§€
  const toggleAnalysis = async () => {
    if (!isServerConnected) {
      alert('ì„œë²„ì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
      return;
    }

    if (!isAnalyzing) {
        setVoiceAnalysisReport(null);
        setShowVoiceReport(false);
      try {
        await fetch(`${BASE_URL}/start_analysis`, { method: 'POST' });
        
        if (deviceInfo.isMobile || deviceInfo.isTablet) {
          setIsOverlayMode(true);
        }
      } catch (error) {
        console.error('ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨:', error);
      }
      
      setCurrentIssues([]);
      setPostureScore(100);
      setVideoError(false);
      lastSpokenIssueRef.current = '';
      lastIssueTimeRef.current = {};
    } else {
      try {
        await fetch(`${BASE_URL}/stop_analysis`, { method: 'POST' });
        stopSpeech();
        stopVoiceAnalysis();
        setIsOverlayMode(false);
        
        if (interviewData.active) {
          await stopInterview();
        }
      } catch (error) {
        console.error('ë¶„ì„ ì¤‘ì§€ ì‹¤íŒ¨:', error);
      }
    }
    
    setIsAnalyzing(!isAnalyzing);
  };

  // ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ê°•ì œ í™•ì¸ í•¨ìˆ˜
  const forceCheckVoiceReport = async () => {
    try {
      console.log('ğŸ” ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ê°•ì œ í™•ì¸...');
      const response = await fetch(`${BASE_URL}/voice/analysis_report`);
      const data = await response.json();
      
      if (data.overall_score !== undefined) {
        console.log('âœ… ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ë°œê²¬:', data);
        setVoiceAnalysisReport(data);
        setShowVoiceReport(true);
      } else {
        console.log('âŒ ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ:', data);
      }
    } catch (error) {
      console.error('ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ê°•ì œ í™•ì¸ ì‹¤íŒ¨:', error);
    }
  };

  // ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
  const getScoreClass = (score) => {
    if (score >= 80) return 'score-excellent';
    if (score >= 60) return 'score-good';
    return 'score-poor';
  };

  const getPhaseText = (phase) => {
    switch (phase) {
      case 'thinking': return 'ìƒê° ì‹œê°„';
      case 'answering': return 'ë‹µë³€ ì‹œê°„';
      case 'finished': return 'ì™„ë£Œ';
      default: return 'ëŒ€ê¸°';
    }
  };

  const getPhaseColor = (phase) => {
    switch (phase) {
      case 'thinking': return 'phase-thinking';
      case 'answering': return 'phase-answering';
      case 'finished': return 'phase-finished';
      default: return 'phase-waiting';
    }
  };

  const getVoiceLevelColor = (level) => {
    if (level < 20) return '#999';
    if (level < 50) return '#ffeb3b';
    if (level < 80) return '#4caf50';
    return '#ff5722';
  };

  // ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ì»´í¬ë„ŒíŠ¸
// ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸ ì»´í¬ë„ŒíŠ¸ (ì•½ 1320ë²ˆì§¸ ì¤„)
const VoiceAnalysisReport = () => {
    if (!voiceAnalysisReport || !showVoiceReport) return null;
  
    const hasAI = voiceAnalysisReport.ai_powered;
    const aiDetails = voiceAnalysisReport.ai_details;
    const details = voiceAnalysisReport.detailed_analysis;
  
    return (
      <div 
        className="voice-report-modal" 
        onClick={() => setShowVoiceReport(false)}
      >
        <div 
          className="voice-report-content"
          onClick={(e) => e.stopPropagation()}
        >
          <div className="voice-report-header">
            <h2>ğŸ¤ ìŒì„± ë¶„ì„ ê²°ê³¼ {hasAI && <span style={{fontSize: '14px', color: '#4CAF50'}}>ğŸ¤– AI ë¶„ì„</span>}</h2>
            <button 
              className="voice-report-close"
              onClick={(e) => {
                e.stopPropagation();
                setShowVoiceReport(false);
              }}
            >
              âœ•
            </button>
          </div>
          
          <div className="voice-report-body">
            <div className="voice-overall-score">
              <div className="score-circle">
                <span className="score-value">{voiceAnalysisReport.overall_score}</span>
                <span className="score-label">ì¢…í•© ì ìˆ˜</span>
              </div>
            </div>
            
            <div className="voice-details">
              <div className="voice-metric">
                <span className="metric-label">ìŒì„± ìì‹ ê°</span>
                <div className="metric-bar">
                  <div 
                    className="metric-fill" 
                    style={{ width: `${details.voice_confidence}%` }}
                  ></div>
                </div>
                <span className="metric-value">{details.voice_confidence}%</span>
              </div>
              
              <div className="voice-metric">
                <span className="metric-label">ìŒëŸ‰ ì¼ê´€ì„±</span>
                <div className="metric-bar">
                  <div 
                    className="metric-fill" 
                    style={{ width: `${details.volume_consistency}%` }}
                  ></div>
                </div>
                <span className="metric-value">{details.volume_consistency}%</span>
              </div>
              
              <div className="voice-metric">
                <span className="metric-label">ìŒì„± ì•ˆì •ì„±</span>
                <div className="metric-bar">
                  <div 
                    className="metric-fill" 
                    style={{ width: `${details.voice_stability}%` }}
                  ></div>
                </div>
                <span className="metric-value">{details.voice_stability}%</span>
              </div>
              
              {/* ğŸ”§ AI ë¶„ì„ ì¶”ê°€ í•­ëª© */}
              {hasAI && details.jitter_percent !== undefined && (
                <div className="voice-metric">
                  <span className="metric-label">ğŸ¤– ìŒì • ë–¨ë¦¼ (Jitter)</span>
                  <div className="metric-bar">
                    <div 
                      className="metric-fill" 
                      style={{ 
                        width: `${Math.max(0, 100 - details.jitter_percent * 20)}%`,
                        backgroundColor: details.jitter_percent < 2 ? '#4CAF50' : details.jitter_percent < 3.5 ? '#FFC107' : '#F44336'
                      }}
                    ></div>
                  </div>
                  <span className="metric-value">{details.jitter_percent.toFixed(2)}%</span>
                </div>
              )}
              
              {hasAI && details.average_pitch !== undefined && (
                <div className="voice-metric">
                  <span className="metric-label">ğŸ¤– í‰ê·  ìŒë†’ì´</span>
                  <div className="metric-bar">
                    <div 
                      className="metric-fill" 
                      style={{ width: '70%', backgroundColor: '#2196F3' }}
                    ></div>
                  </div>
                  <span className="metric-value">{details.average_pitch.toFixed(0)} Hz</span>
                </div>
              )}
              
              {hasAI && details.vocabulary_richness !== undefined && (
                <div className="voice-metric">
                  <span className="metric-label">ğŸ¤– ì–´íœ˜ ë‹¤ì–‘ì„±</span>
                  <div className="metric-bar">
                    <div 
                      className="metric-fill" 
                      style={{ width: `${details.vocabulary_richness}%` }}
                    ></div>
                  </div>
                  <span className="metric-value">{details.vocabulary_richness.toFixed(1)}%</span>
                </div>
              )}
              
              <div className="voice-stats">
                <div className="stat-item">
                  <span className="stat-label">ë§í•˜ê¸° ì‹œê°„</span>
                  <span className="stat-value">{details.total_speaking_time}ì´ˆ</span>
                </div>
                <div className="stat-item">
                  <span className="stat-label">ì¶”ì„ìƒˆ ì‚¬ìš©</span>
                  <span className="stat-value">
                    {details.filler_word_count}íšŒ ({details.filler_ratio}%)
                  </span>
                </div>
                {hasAI && details.connective_count !== undefined && (
                  <div className="stat-item">
                    <span className="stat-label">ğŸ¤– ì ‘ì†ì‚¬ ì‚¬ìš©</span>
                    <span className="stat-value">{details.connective_count}íšŒ</span>
                  </div>
                )}
                {hasAI && details.avg_sentence_length !== undefined && (
                  <div className="stat-item">
                    <span className="stat-label">ğŸ¤– í‰ê·  ë¬¸ì¥ ê¸¸ì´</span>
                    <span className="stat-value">{details.avg_sentence_length.toFixed(1)}ë‹¨ì–´</span>
                  </div>
                )}
              </div>
            </div>
            
            {/* ğŸ”§ AI ì¸ì‹ëœ í…ìŠ¤íŠ¸ í‘œì‹œ */}
            {hasAI && aiDetails && aiDetails.recognized_text && (
              <div className="voice-recognized-text" style={{
                background: '#f5f5f5',
                padding: '15px',
                borderRadius: '8px',
                margin: '15px 0',
                maxHeight: '150px',
                overflow: 'auto'
              }}>
                <h4 style={{margin: '0 0 10px 0', fontSize: '14px', color: '#666'}}>
                  ğŸ¤– Whisper ì¸ì‹ í…ìŠ¤íŠ¸:
                </h4>
                <p style={{margin: 0, fontSize: '13px', lineHeight: '1.6', color: '#333'}}>
                  {aiDetails.recognized_text}
                </p>
              </div>
            )}
            
            {/* ğŸ”§ AI ìƒì„¸ ë¶„ì„ (ì ‘ì†ì‚¬, ì¶”ì„ìƒˆ ì¢…ë¥˜) */}
            {hasAI && aiDetails && (
              <div className="ai-details" style={{
                background: '#e3f2fd',
                padding: '15px',
                borderRadius: '8px',
                margin: '15px 0'
              }}>
                <h4 style={{margin: '0 0 10px 0', fontSize: '14px', color: '#1976D2'}}>
                  ğŸ¤– AI ìƒì„¸ ë¶„ì„
                </h4>
                
                {aiDetails.filler_words && Object.keys(aiDetails.filler_words).length > 0 && (
                  <div style={{marginBottom: '10px'}}>
                    <strong style={{fontSize: '13px'}}>ì¶”ì„ìƒˆ ë¶„ì„:</strong>
                    <div style={{fontSize: '12px', marginTop: '5px'}}>
                      {Object.entries(aiDetails.filler_words).map(([word, count]) => (
                        <span key={word} style={{
                          display: 'inline-block',
                          background: '#fff',
                          padding: '3px 8px',
                          borderRadius: '12px',
                          margin: '3px',
                          border: '1px solid #ddd'
                        }}>
                          "{word}" {count}íšŒ
                        </span>
                      ))}
                    </div>
                  </div>
                )}
                
                {aiDetails.connectives && Object.keys(aiDetails.connectives).length > 0 && (
                  <div style={{marginBottom: '10px'}}>
                    <strong style={{fontSize: '13px'}}>ì ‘ì†ì‚¬ ë¶„ì„:</strong>
                    <div style={{fontSize: '12px', marginTop: '5px'}}>
                      {Object.entries(aiDetails.connectives).map(([word, count]) => (
                        <span key={word} style={{
                          display: 'inline-block',
                          background: '#fff',
                          padding: '3px 8px',
                          borderRadius: '12px',
                          margin: '3px',
                          border: '1px solid #ddd'
                        }}>
                          "{word}" {count}íšŒ
                        </span>
                      ))}
                    </div>
                  </div>
                )}
                
                {aiDetails.top_nouns && Object.keys(aiDetails.top_nouns).length > 0 && (
                  <div>
                    <strong style={{fontSize: '13px'}}>ìì£¼ ì‚¬ìš©í•œ ë‹¨ì–´:</strong>
                    <div style={{fontSize: '12px', marginTop: '5px'}}>
                      {Object.entries(aiDetails.top_nouns).slice(0, 8).map(([word, count]) => (
                        <span key={word} style={{
                          display: 'inline-block',
                          background: '#fff',
                          padding: '3px 8px',
                          borderRadius: '12px',
                          margin: '3px',
                          border: '1px solid #ddd'
                        }}>
                          "{word}" {count}íšŒ
                        </span>
                      ))}
                    </div>
                  </div>
                )}
              </div>
            )}
            
            <div className="voice-recommendations">
              <h3>ğŸ“‹ ê°œì„  ì œì•ˆ</h3>
              <ul>
                {voiceAnalysisReport.recommendations.map((rec, index) => (
                  <li key={index}>{rec}</li>
                ))}
              </ul>
            </div>
            
            {/* ë””ë²„ê·¸ ì •ë³´ */}
            {voiceAnalysisReport.debug_info && (
              <div style={{
                fontSize: '11px',
                color: '#999',
                marginTop: '15px',
                padding: '10px',
                background: '#fafafa',
                borderRadius: '4px'
              }}>
                <div>ë¶„ì„ ìƒ˜í”Œ: {voiceAnalysisReport.debug_info.samples_analyzed}ê°œ</div>
                <div>ì²­í¬ ìˆ˜ì‹ : {voiceAnalysisReport.debug_info.chunks_received}ê°œ</div>
                {hasAI && (
                  <>
                    <div>âœ… Whisper: {voiceAnalysisReport.debug_info.has_whisper ? 'í™œì„±' : 'ë¹„í™œì„±'}</div>
                    <div>âœ… librosa: {voiceAnalysisReport.debug_info.has_librosa ? 'í™œì„±' : 'ë¹„í™œì„±'}</div>
                  </>
                )}
              </div>
            )}
          </div>
        </div>
      </div>
    );
  };

  // ğŸ”§ ì¶”ê°€: ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í‘œì‹œ ì»´í¬ë„ŒíŠ¸
  const MicTestResults = () => {
    if (!micTestResults || micTestResults.error) return null;

    return (
      <div style={{
        background: micTestResults.signalDetected 
          ? 'rgba(76, 175, 80, 0.1)' 
          : 'rgba(244, 67, 54, 0.1)',
        border: `2px solid ${micTestResults.signalDetected ? '#4CAF50' : '#F44336'}`,
        borderRadius: '8px',
        padding: '12px',
        margin: '10px 0',
        fontSize: '14px'
      }}>
        <div style={{ fontWeight: 'bold', marginBottom: '8px' }}>
          ğŸ§ª ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼:
        </div>
        <div>
          ìµœëŒ€ ë³¼ë¥¨: {micTestResults.maxVolume.toFixed(1)}% | 
          í‰ê·  ë³¼ë¥¨: {micTestResults.avgVolume.toFixed(1)}% | 
          ì‹ í˜¸ ê°ì§€: {micTestResults.signalDetected ? 'âœ…' : 'âŒ'}
        </div>
        {micTestResults.signalDetected && micTestResults.maxVolume > 20 && (
          <div style={{ color: '#4CAF50', fontWeight: 'bold' }}>
            âœ… ë§ˆì´í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤! ë©´ì ‘ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
          </div>
        )}
      </div>
    );
  };

  // ì˜¤ë²„ë ˆì´ ëª¨ë“œ (ëª¨ë°”ì¼/íƒœë¸”ë¦¿)
  if (isOverlayMode && (deviceInfo.isMobile || deviceInfo.isTablet)) {
    return (
      <div className={`overlay-container ${deviceInfo.orientation}`}>
        <div className="video-overlay">
          {isAnalyzing && isServerConnected ? (
            <>
              <img 
                ref={imgRef}
                src={`${BASE_URL}/video_feed`}
                alt="Video Feed"
                className={`overlay-video ${videoError ? 'hidden' : ''}`}
                onError={() => setVideoError(true)}
                onLoad={() => setVideoError(false)}
              />
              
              {videoError && (
                <div className="video-loading">
                  <Camera />
                  <p>ë¹„ë””ì˜¤ ë¡œë”© ì¤‘...</p>
                </div>
              )}
              
              {/* ë©´ì ‘ ì§ˆë¬¸ ì˜¤ë²„ë ˆì´ */}
              {interviewData.active && interviewData.current_question && (
  <div className={`interview-overlay-mobile ${deviceInfo.orientation}`}>
    <div className="interview-header-mobile">
      <span className="question-number-mobile">Q{interviewData.question_number}/{interviewData.total_questions}</span>
      <span className="category-badge-mobile">{interviewData.category}</span>
    </div>
    
    <div className={`phase-indicator-mobile ${getPhaseColor(interviewData.phase)}`}>
      {interviewData.phase === 'thinking' && <Brain />}
      {getPhaseText(interviewData.phase)}: {interviewData.time_remaining}ì´ˆ
    </div>
    
    {/* ì§ˆë¬¸ í…ìŠ¤íŠ¸ - ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•˜ê²Œ */}
    <div className="interview-question-mobile">
      {interviewData.current_question}
    </div>
    
    {/* ìŒì„± ë¶„ì„ - ê°„ì†Œí™” */}
    {voiceAnalysisActive && interviewData.phase === 'answering' && (
      <div className="voice-analysis-mobile">
        <Mic />
        <div 
          className="voice-level-bar-mobile"
          style={{ 
            width: `${voiceLevel}%`,
            backgroundColor: getVoiceLevelColor(voiceLevel)
          }}
        ></div>
        <span style={{fontSize: '12px', minWidth: '40px'}}>{Math.round(voiceLevel)}%</span>
      </div>
    )}
    
    <button 
      className="stop-interview-btn-mobile"
      onClick={stopInterview}
    >
      ë©´ì ‘ ì¤‘ì§€
    </button>
  </div>
)}
              
              {/* ìì„¸ í”¼ë“œë°± */}
              {!interviewData.active && currentIssues.length > 0 && (
                <div className={`issues-overlay-mobile ${deviceInfo.orientation}`}>
                  <AlertCircle className="icon-alert" />
                  <div className="issues-text">
                    {currentIssues.map((issue, idx) => (
                      <div key={idx}>{issue}</div>
                    ))}
                  </div>
                </div>
              )}
              
              {/* ì ìˆ˜ ì˜¤ë²„ë ˆì´ */}
              <div className={`score-overlay-mobile ${getScoreClass(postureScore)} ${deviceInfo.orientation} ${interviewData.active ? 'with-interview' : ''}`}>
                {postureScore}
              </div>
              
              {/* ì»¨íŠ¸ë¡¤ ì˜¤ë²„ë ˆì´ */}
              <div className={`controls-overlay ${deviceInfo.orientation} ${interviewData.active ? 'with-interview' : ''}`}>
                <button 
                  className={`voice-btn-overlay ${voiceEnabled ? 'voice-on' : 'voice-off'}`}
                  onClick={() => setVoiceEnabled(!voiceEnabled)}
                >
                  {voiceEnabled ? <Volume2 /> : <VolumeX />}
                </button>
                
                <button 
                  className={`voice-analysis-btn-overlay ${voiceAnalysisEnabled ? 'analysis-on' : 'analysis-off'}`}
                  onClick={() => setVoiceAnalysisEnabled(!voiceAnalysisEnabled)}
                >
                  {voiceAnalysisEnabled ? <Mic /> : <MicOff />}
                </button>
                
                {!interviewData.active && (
                  <button 
                    className="interview-btn-overlay"
                    onClick={startInterview}
                  >
                    <MessageSquare />
                  </button>
                )}
                
                {showVoiceReport && (
                  <button 
                    className="voice-report-btn-overlay"
                    onClick={() => setShowVoiceReport(true)}
                  >
                    <BarChart />
                  </button>
                )}
                
                <button 
                  className="stop-btn-overlay"
                  onClick={toggleAnalysis}
                >
                  ì¤‘ì§€
                </button>
              </div>
            </>
          ) : (
            <div className="overlay-placeholder">
              <Camera />
              <p>ë¶„ì„ ì‹œì‘ ì¤‘...</p>
            </div>
          )}
        </div>
        
        <VoiceAnalysisReport />
      </div>
    );
  }

  // ì¼ë°˜ ëª¨ë“œ (ë°ìŠ¤í¬íƒ‘)
  return (
    <div className="app-container">
      <div className="header">
        <h1>ì²´ìœ¡ëŒ€í•™ ìœ¡ìƒì „ê³µ ë©´ì ‘ ì—°ìŠµ (ìì„¸ + ìŒì„± ë¶„ì„)</h1>
        <div className={`connection-status ${isServerConnected ? 'connected' : 'disconnected'}`}>
          {isServerConnected ? 'ì—°ê²°ë¨' : 'ì„œë²„ ì—°ê²° ì•ˆë¨'}
        </div>
      </div>

      {/* ğŸ”§ ì¶”ê°€: ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì„¹ì…˜ */}
      {!isAnalyzing && (
        <div className="mic-test-section" style={{
          background: 'linear-gradient(135deg, #667eea, #764ba2)',
          color: 'white',
          padding: '20px',
          borderRadius: '12px',
          margin: '20px 0',
          textAlign: 'center'
        }}>
          <h3 style={{ margin: '0 0 15px 0' }}>ğŸ§ª ë§ˆì´í¬ í…ŒìŠ¤íŠ¸</h3>
          <p style={{ margin: '0 0 15px 0', opacity: 0.9 }}>
            ë©´ì ‘ ì‹œì‘ ì „ì— ë§ˆì´í¬ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”
          </p>
          
          <button
            onClick={micTestActive ? stopMicTest : runMicrophoneTest}
            disabled={isAnalyzing && !micTestActive}
            style={{
              background: micTestActive 
                ? 'linear-gradient(135deg, #ff6b6b, #ee5a24)' 
                : 'linear-gradient(135deg, #00d2ff, #3a7bd5)',
              color: 'white',
              border: 'none',
              padding: '15px 30px',
              borderRadius: '8px',
              cursor: 'pointer',
              fontSize: '16px',
              fontWeight: 'bold',
              margin: '0 10px'
            }}
          >
            {micTestActive ? 'ğŸ›‘ í…ŒìŠ¤íŠ¸ ì¤‘ì§€' : 'ğŸ§ª ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹œì‘'}
          </button>
          
          {micTestActive && (
            <div style={{ marginTop: '15px' }}>
              <div style={{ fontSize: '14px', marginBottom: '10px' }}>
                ğŸ—£ï¸ ì§€ê¸ˆ ë§ˆì´í¬ì— ë§í•´ë³´ì„¸ìš”! (10ì´ˆê°„ í…ŒìŠ¤íŠ¸)
              </div>
              <div style={{
                background: 'rgba(255,255,255,0.2)',
                borderRadius: '20px',
                height: '8px',
                overflow: 'hidden',
                margin: '10px auto',
                width: '200px'
              }}>
                <div style={{
                  width: `${voiceLevel}%`,
                  height: '100%',
                  background: getVoiceLevelColor(voiceLevel),
                  transition: 'width 0.1s ease'
                }}></div>
              </div>
              <div style={{ fontSize: '12px' }}>
                ë³¼ë¥¨: {Math.round(voiceLevel)}%
              </div>
            </div>
          )}
          
          <MicTestResults />
        </div>
      )}

      {/* ë©´ì ‘ ì§ˆë¬¸ íŒ¨ë„ */}
      {interviewData.active && interviewData.current_question && (
        <div className="interview-panel">
          <div className="interview-info">
            <div className="interview-meta">
              <span className="question-counter">ì§ˆë¬¸ {interviewData.question_number}/{interviewData.total_questions}</span>
              <span className="category-badge">{interviewData.category}</span>
              <span className={`phase-indicator ${getPhaseColor(interviewData.phase)}`}>
                {interviewData.phase === 'thinking' && <Brain />}
                {getPhaseText(interviewData.phase)}: {interviewData.time_remaining}ì´ˆ
              </span>
            </div>
            
            <div className="current-question">
              {interviewData.current_question}
            </div>
            
            {/* ìŒì„± ë¶„ì„ ìƒíƒœ í‘œì‹œ */}
            {voiceAnalysisActive && (
              <div className="voice-analysis-panel">
                <div className="voice-indicator">
                  <Mic />
                  <span>ìŒì„± ë¶„ì„ ì¤‘ (MediaRecorder)</span>
                  <div className="voice-level-bar">
                    <div 
                      className="voice-level-fill"
                      style={{ 
                        width: `${voiceLevel}%`,
                        backgroundColor: getVoiceLevelColor(voiceLevel)
                      }}
                    ></div>
                  </div>
                  <span className="voice-level-text">{Math.round(voiceLevel)}%</span>
                </div>
              </div>
            )}
            
            <div className="interview-controls">
              <button 
                className="btn-stop-interview"
                onClick={stopInterview}
              >
                ë©´ì ‘ ì¤‘ì§€
              </button>
              
              {/* ìŒì„± ë¶„ì„ ìƒíƒœ í‘œì‹œ */}
              {voiceAnalysisEnabled && (
                <div className="voice-analysis-status">
                  <span className={`voice-status-indicator ${voiceAnalysisActive ? 'active' : 'inactive'}`}>
                    <Mic />
                    {voiceAnalysisActive ? 'MediaRecorder í™œì„±' : 'MediaRecorder ëŒ€ê¸°'}
                  </span>
                </div>
              )}
            </div>
          </div>
        </div>
      )}

      <div className="video-container">
        {isAnalyzing && isServerConnected ? (
          <>
            <img 
              ref={imgRef}
              src={`${BASE_URL}/video_feed`}
              alt="Video Feed"
              className={`video-feed ${videoError ? 'hidden' : ''}`}
              onError={() => setVideoError(true)}
              onLoad={() => setVideoError(false)}
            />
            
            {videoError && (
              <div className="video-loading">
                <Camera />
                <p>ë¹„ë””ì˜¤ ë¡œë”© ì¤‘...</p>
              </div>
            )}
            
            {/* ë©´ì ‘ ì¤‘ì´ ì•„ë‹ ë•Œë§Œ ìì„¸ í”¼ë“œë°± í‘œì‹œ */}
            {!interviewData.active && currentIssues.length > 0 && (
              <div className="issues-overlay">
                <AlertCircle className="icon-alert" />
                <div className="issues-text">
                  {currentIssues.map((issue, idx) => (
                    <div key={idx}>{issue}</div>
                  ))}
                </div>
              </div>
            )}
            
            <div className={`score-overlay ${getScoreClass(postureScore)}`}>
              {postureScore}
            </div>
          </>
        ) : (
          <div className="video-placeholder">
            <Camera />
            <p>ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”</p>
            {!isServerConnected && (
              <p className="error-message">ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤</p>
            )}
          </div>
        )}
      </div>

      <div className="controls">
        <button
          onClick={toggleAnalysis}
          disabled={!isServerConnected}
          className={`btn-main ${!isServerConnected ? 'disabled' : isAnalyzing ? 'stop' : 'start'}`}
        >
          {isAnalyzing ? 'ë¶„ì„ ì¤‘ì§€' : 'ë¶„ì„ ì‹œì‘'}
        </button>
        
        {isAnalyzing && !interviewData.active && (
          <button
            onClick={startInterview}
            className="btn-interview"
          >
            <MessageSquare />
            ë©´ì ‘ ì‹œì‘
          </button>
        )}
        
        <button
          onClick={() => {
            setVoiceEnabled(!voiceEnabled);
            if (!voiceEnabled && interviewData.current_question && interviewData.phase === 'thinking') {
              setTimeout(() => speakQuestion(interviewData.current_question), 500);
            } else {
              stopSpeech();
            }
          }}
          className={`btn-voice ${voiceEnabled ? 'voice-on' : 'voice-off'}`}
        >
          {voiceEnabled ? <Volume2 /> : <VolumeX />}
          {voiceEnabled ? ' ìŒì„± ON' : ' ìŒì„± OFF'}
        </button>
        
        <button
          onClick={() => setVoiceAnalysisEnabled(!voiceAnalysisEnabled)}
          className={`btn-voice-analysis ${voiceAnalysisEnabled ? 'analysis-on' : 'analysis-off'}`}
        >
          {voiceAnalysisEnabled ? <Mic /> : <MicOff />}
          {voiceAnalysisEnabled ? ' MediaRecorder ON' : ' MediaRecorder OFF'}
        </button>
        
        {voiceAnalysisReport && (
          <button
            onClick={() => setShowVoiceReport(true)}
            className="btn-voice-report"
          >
            <BarChart />
            ìŒì„± ë¶„ì„ ê²°ê³¼
          </button>
        )}
        
        {/* ğŸ”§ ë””ë²„ê·¸ ë²„íŠ¼ */}
        {!interviewData.active && (
          <button
            onClick={forceCheckVoiceReport}
            className="btn-debug"
            style={{
              background: 'linear-gradient(135deg, #ff6b6b, #ee5a24)',
              color: 'white',
              border: 'none',
              padding: '12px 20px',
              borderRadius: '8px',
              cursor: 'pointer'
            }}
          >
            ğŸ” ë¦¬í¬íŠ¸ í™•ì¸
          </button>
        )}
      </div>

      {/* ë©´ì ‘ ì•ˆë‚´ */}
      {isAnalyzing && !interviewData.active && (
        <div className="interview-guide">
          <h3>ğŸ¯ ë©´ì ‘ ì—°ìŠµ ê°€ì´ë“œ (ìì„¸ + MediaRecorder ìŒì„± ë¶„ì„)</h3>
          <div className="guide-content">
            <div className="guide-item">
              <span className="guide-icon">ğŸ’­</span>
              <span>ì§ˆë¬¸ í›„ <strong>10ì´ˆ ìƒê° ì‹œê°„</strong>ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ—£ï¸</span>
              <span><strong>50ì´ˆ ë‹µë³€ ì‹œê°„</strong> ë™ì•ˆ ììœ ë¡­ê²Œ ë‹µë³€í•˜ì„¸ìš”</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ¤</span>
              <span><strong>MediaRecorder API</strong>ë¡œ ìŒì„±ì„ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ“Š</span>
              <span>ë©´ì ‘ ì™„ë£Œ í›„ <strong>ì¢…í•© ìŒì„± ë¶„ì„ ë¦¬í¬íŠ¸</strong>ë¥¼ ì œê³µí•©ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ”„</span>
              <span>ì‹œê°„ì´ ì§€ë‚˜ë©´ <strong>ìë™ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸</strong>ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ“‹</span>
              <span>ì´ <strong>6ê°œì˜ ì²´ê³„ì  ì§ˆë¬¸</strong>ì´ ì¶œì œë©ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸŒ</span>
              <span><strong>HTTP í™˜ê²½</strong>ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤</span>
            </div>
            <div className="guide-item">
              <span className="guide-icon">ğŸ¯</span>
              <span className={`voice-analysis-guide ${voiceAnalysisActive ? 'active' : 'inactive'}`}>
                MediaRecorder: {voiceAnalysisActive ? 'âœ… í™œì„±í™”ë¨' : 'â¸ï¸ ëŒ€ê¸° ì¤‘'}
              </span>
            </div>
          </div>
        </div>
      )}
      
      <VoiceAnalysisReport />
    </div>
  );
}
